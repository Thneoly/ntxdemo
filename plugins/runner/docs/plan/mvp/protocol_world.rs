// Generated by `wit-bindgen` 0.48.0. DO NOT EDIT!
// Options used:
#[allow(dead_code, clippy::all)]
pub mod ntx {
  pub mod runner {
    /// Common data structures shared across Core, ProtocolFrame, and Protocol definitions.
    #[allow(dead_code, async_fn_in_trait, unused_imports, clippy::all)]
    pub mod types {
      #[used]
      #[doc(hidden)]
      static __FORCE_SECTION_REF: fn() =
      super::super::super::__link_custom_section_describing_imports;
      
      use super::super::super::_rt;
      /// Stable identifier for a workflow task.
      pub type TaskId = _rt::String;
      /// Stable identifier for a single logical user.
      pub type UserId = _rt::String;
      /// Identifier for an action node within a task tree.
      pub type ActionId = _rt::String;
      /// Supported protocol flavors.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ProtocolKind {
        Http,
        Ftp,
        TcpProbe,
        Custom,
      }
      impl ::core::fmt::Debug for ProtocolKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ProtocolKind::Http => {
              f.debug_tuple("ProtocolKind::Http").finish()
            }
            ProtocolKind::Ftp => {
              f.debug_tuple("ProtocolKind::Ftp").finish()
            }
            ProtocolKind::TcpProbe => {
              f.debug_tuple("ProtocolKind::TcpProbe").finish()
            }
            ProtocolKind::Custom => {
              f.debug_tuple("ProtocolKind::Custom").finish()
            }
          }
        }
      }

      impl ProtocolKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ProtocolKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ProtocolKind::Http,
            1 => ProtocolKind::Ftp,
            2 => ProtocolKind::TcpProbe,
            3 => ProtocolKind::Custom,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Tracks whether an action originates from Host scripts or runtime extensions.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionOrigin {
        HostScript,
        RuntimeGenerated,
      }
      impl ::core::fmt::Debug for ActionOrigin {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionOrigin::HostScript => {
              f.debug_tuple("ActionOrigin::HostScript").finish()
            }
            ActionOrigin::RuntimeGenerated => {
              f.debug_tuple("ActionOrigin::RuntimeGenerated").finish()
            }
          }
        }
      }

      impl ActionOrigin{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionOrigin{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionOrigin::HostScript,
            1 => ActionOrigin::RuntimeGenerated,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Scheduler lifecycle markers for actions.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionPhase {
        Pending,
        Running,
        Waiting,
        Retrying,
        Completed,
        Failed,
      }
      impl ::core::fmt::Debug for ActionPhase {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionPhase::Pending => {
              f.debug_tuple("ActionPhase::Pending").finish()
            }
            ActionPhase::Running => {
              f.debug_tuple("ActionPhase::Running").finish()
            }
            ActionPhase::Waiting => {
              f.debug_tuple("ActionPhase::Waiting").finish()
            }
            ActionPhase::Retrying => {
              f.debug_tuple("ActionPhase::Retrying").finish()
            }
            ActionPhase::Completed => {
              f.debug_tuple("ActionPhase::Completed").finish()
            }
            ActionPhase::Failed => {
              f.debug_tuple("ActionPhase::Failed").finish()
            }
          }
        }
      }

      impl ActionPhase{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionPhase{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionPhase::Pending,
            1 => ActionPhase::Running,
            2 => ActionPhase::Waiting,
            3 => ActionPhase::Retrying,
            4 => ActionPhase::Completed,
            5 => ActionPhase::Failed,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Result classification produced by Protocol implementations.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionResultKind {
        Success,
        Skipped,
        Failed,
      }
      impl ::core::fmt::Debug for ActionResultKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionResultKind::Success => {
              f.debug_tuple("ActionResultKind::Success").finish()
            }
            ActionResultKind::Skipped => {
              f.debug_tuple("ActionResultKind::Skipped").finish()
            }
            ActionResultKind::Failed => {
              f.debug_tuple("ActionResultKind::Failed").finish()
            }
          }
        }
      }

      impl ActionResultKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionResultKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionResultKind::Success,
            1 => ActionResultKind::Skipped,
            2 => ActionResultKind::Failed,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// High-level errors surfaced by the scheduler.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum SchedulerErrorKind {
        InvalidCtx,
        Capacity,
        Io,
        Timeout,
        Internal,
      }
      impl ::core::fmt::Debug for SchedulerErrorKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            SchedulerErrorKind::InvalidCtx => {
              f.debug_tuple("SchedulerErrorKind::InvalidCtx").finish()
            }
            SchedulerErrorKind::Capacity => {
              f.debug_tuple("SchedulerErrorKind::Capacity").finish()
            }
            SchedulerErrorKind::Io => {
              f.debug_tuple("SchedulerErrorKind::Io").finish()
            }
            SchedulerErrorKind::Timeout => {
              f.debug_tuple("SchedulerErrorKind::Timeout").finish()
            }
            SchedulerErrorKind::Internal => {
              f.debug_tuple("SchedulerErrorKind::Internal").finish()
            }
          }
        }
      }

      impl SchedulerErrorKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> SchedulerErrorKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => SchedulerErrorKind::InvalidCtx,
            1 => SchedulerErrorKind::Capacity,
            2 => SchedulerErrorKind::Io,
            3 => SchedulerErrorKind::Timeout,
            4 => SchedulerErrorKind::Internal,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Errors emitted by ProtocolFrame services.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum PfErrorKind {
        InvalidRequest,
        Throttled,
        NotFound,
        Internal,
      }
      impl ::core::fmt::Debug for PfErrorKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            PfErrorKind::InvalidRequest => {
              f.debug_tuple("PfErrorKind::InvalidRequest").finish()
            }
            PfErrorKind::Throttled => {
              f.debug_tuple("PfErrorKind::Throttled").finish()
            }
            PfErrorKind::NotFound => {
              f.debug_tuple("PfErrorKind::NotFound").finish()
            }
            PfErrorKind::Internal => {
              f.debug_tuple("PfErrorKind::Internal").finish()
            }
          }
        }
      }

      impl PfErrorKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> PfErrorKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => PfErrorKind::InvalidRequest,
            1 => PfErrorKind::Throttled,
            2 => PfErrorKind::NotFound,
            3 => PfErrorKind::Internal,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      wit_bindgen::rt::bitflags::bitflags! {
        /// Capability flags advertised by ProtocolFrame to Protocol implementations.
        #[derive(PartialEq, Eq, PartialOrd, Ord, Hash, Debug, Clone, Copy)]
        pub struct PfCapability: u8 {
          const LOGGER = 1 << 0;
          const TIMER = 1 << 1;
          const SOCKET = 1 << 2;
          const RATE_GUARD = 1 << 3;
          const PROGRESS = 1 << 4;
          const CALL_MODEL = 1 << 5;
        }
      }
      /// Configures scheduler invariants for a workflow.
      #[derive(Clone)]
      pub struct SchedulerConfig {
        pub workflow_id: _rt::String,
        pub tick_duration_ms: u32,
        pub max_concurrency: u32,
        pub warmup_ticks: Option<u32>,
      }
      impl ::core::fmt::Debug for SchedulerConfig {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("SchedulerConfig").field("workflow-id", &self.workflow_id).field("tick-duration-ms", &self.tick_duration_ms).field("max-concurrency", &self.max_concurrency).field("warmup-ticks", &self.warmup_ticks).finish()
        }
      }
      /// Describes the rate settings Core applies per action.
      #[repr(C)]
      #[derive(Clone, Copy)]
      pub struct RateProfile {
        pub bytes_per_tick: u32,
        pub max_burst_bytes: Option<u32>,
        pub max_inflight: Option<u32>,
      }
      impl ::core::fmt::Debug for RateProfile {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("RateProfile").field("bytes-per-tick", &self.bytes_per_tick).field("max-burst-bytes", &self.max_burst_bytes).field("max-inflight", &self.max_inflight).finish()
        }
      }
      /// Canonical metadata for a task registered with the scheduler.
      #[derive(Clone)]
      pub struct TaskMeta {
        pub task_id: TaskId,
        pub workflow_id: _rt::String,
        pub protocol: ProtocolKind,
        pub priority: u8,
        pub template_ref: Option<_rt::String>,
        pub origin: ActionOrigin,
      }
      impl ::core::fmt::Debug for TaskMeta {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("TaskMeta").field("task-id", &self.task_id).field("workflow-id", &self.workflow_id).field("protocol", &self.protocol).field("priority", &self.priority).field("template-ref", &self.template_ref).field("origin", &self.origin).finish()
        }
      }
      /// Network endpoint definition reused by Core libs.
      #[derive(Clone)]
      pub struct Endpoint {
        pub host: _rt::String,
        pub port: u16,
        pub tls: Option<bool>,
      }
      impl ::core::fmt::Debug for Endpoint {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("Endpoint").field("host", &self.host).field("port", &self.port).field("tls", &self.tls).finish()
        }
      }
      /// Serialized payload description Core hands to Protocol.
      #[derive(Clone)]
      pub struct PayloadRef {
        pub path: _rt::String,
        pub checksum: Option<_rt::String>,
        pub format: _rt::String,
      }
      impl ::core::fmt::Debug for PayloadRef {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("PayloadRef").field("path", &self.path).field("checksum", &self.checksum).field("format", &self.format).finish()
        }
      }
      /// Fully hydrated action context that Scheduler/PF deliver to Protocol.
      #[derive(Clone)]
      pub struct ActionCtx {
        pub task_id: TaskId,
        pub action_id: ActionId,
        pub user_id: UserId,
        pub protocol: ProtocolKind,
        pub origin: ActionOrigin,
        pub payload: PayloadRef,
        pub rate: Option<RateProfile>,
        pub tick: u64,
        pub attempt: u32,
        pub dependencies: _rt::Vec::<ActionId>,
        pub deadline_ns: Option<u64>,
      }
      impl ::core::fmt::Debug for ActionCtx {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ActionCtx").field("task-id", &self.task_id).field("action-id", &self.action_id).field("user-id", &self.user_id).field("protocol", &self.protocol).field("origin", &self.origin).field("payload", &self.payload).field("rate", &self.rate).field("tick", &self.tick).field("attempt", &self.attempt).field("dependencies", &self.dependencies).field("deadline-ns", &self.deadline_ns).finish()
        }
      }
      /// Outcome reported by Protocol (via PF) back to Core.
      #[derive(Clone)]
      pub struct ActionResult {
        pub ctx: ActionCtx,
        pub phase: ActionPhase,
        pub outcome: ActionResultKind,
        pub progress: f32,
        pub error_message: Option<_rt::String>,
      }
      impl ::core::fmt::Debug for ActionResult {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ActionResult").field("ctx", &self.ctx).field("phase", &self.phase).field("outcome", &self.outcome).field("progress", &self.progress).field("error-message", &self.error_message).finish()
        }
      }
      /// Scheduler response when enqueuing runtime tasks.
      #[derive(Clone)]
      pub struct EnqueueResult {
        pub task_id: TaskId,
        pub accepted: bool,
        pub reason: Option<_rt::String>,
      }
      impl ::core::fmt::Debug for EnqueueResult {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("EnqueueResult").field("task-id", &self.task_id).field("accepted", &self.accepted).field("reason", &self.reason).finish()
        }
      }
      /// Canonical scheduler error container.
      #[derive(Clone)]
      pub struct SchedulerError {
        pub kind: SchedulerErrorKind,
        pub message: _rt::String,
      }
      impl ::core::fmt::Debug for SchedulerError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("SchedulerError").field("kind", &self.kind).field("message", &self.message).finish()
        }
      }
      impl ::core::fmt::Display for SchedulerError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          write!(f, "{:?}", self)
        }
      }
      impl ::core::error::Error for SchedulerError {}
      /// ProtocolFrame level errors.
      #[derive(Clone)]
      pub struct PfError {
        pub kind: PfErrorKind,
        pub message: _rt::String,
      }
      impl ::core::fmt::Debug for PfError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("PfError").field("kind", &self.kind).field("message", &self.message).finish()
        }
      }
      impl ::core::fmt::Display for PfError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          write!(f, "{:?}", self)
        }
      }
      impl ::core::error::Error for PfError {}
      /// Metadata used when ProtocolFrame hands runtime context to Protocol.
      #[derive(Clone)]
      pub struct ProtocolInitCtx {
        pub pf_id: _rt::String,
        pub workflow_id: _rt::String,
        pub capabilities: _rt::Vec::<PfCapability>,
        pub resource_dir: _rt::String,
        pub user_count: u32,
      }
      impl ::core::fmt::Debug for ProtocolInitCtx {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ProtocolInitCtx").field("pf-id", &self.pf_id).field("workflow-id", &self.workflow_id).field("capabilities", &self.capabilities).field("resource-dir", &self.resource_dir).field("user-count", &self.user_count).finish()
        }
      }
      /// Describes the storage slots PF can persist for each user.
      #[derive(Clone)]
      pub struct UserStoreEntry {
        pub user_id: UserId,
        pub blob_path: _rt::String,
        pub updated_at_ns: u64,
      }
      impl ::core::fmt::Debug for UserStoreEntry {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("UserStoreEntry").field("user-id", &self.user_id).field("blob-path", &self.blob_path).field("updated-at-ns", &self.updated_at_ns).finish()
        }
      }

    }

  }
}
#[allow(dead_code, clippy::all)]
pub mod exports {
  pub mod ntx {
    pub mod runner {

      #[allow(dead_code, async_fn_in_trait, unused_imports, clippy::all)]
      pub mod protocol_component {
        #[used]
        #[doc(hidden)]
        static __FORCE_SECTION_REF: fn() =
        super::super::super::super::__link_custom_section_describing_imports;
        
        use super::super::super::super::_rt;
        pub type ProtocolInitCtx = super::super::super::super::ntx::runner::types::ProtocolInitCtx;
        pub type ActionCtx = super::super::super::super::ntx::runner::types::ActionCtx;
        pub type ActionResult = super::super::super::super::ntx::runner::types::ActionResult;
        pub type PfError = super::super::super::super::ntx::runner::types::PfError;

        #[derive(Debug)]
        #[repr(transparent)]
        pub struct Instance{
          handle: _rt::Resource<Instance>,
        }

        type _InstanceRep<T> = Option<T>;

        impl Instance{
          /// Creates a new resource from the specified representation.
          ///
          /// This function will create a new resource handle by moving `val` onto
          /// the heap and then passing that heap pointer to the component model to
          /// create a handle. The owned handle is then returned as `Instance`.
          pub fn new<T: GuestInstance>(val: T) -> Self {
            Self::type_guard::<T>();
            let val: _InstanceRep<T> = Some(val);
            let ptr: *mut _InstanceRep<T> =
            _rt::Box::into_raw(_rt::Box::new(val));
            unsafe {
              Self::from_handle(T::_resource_new(ptr.cast()))
            }
          }

          /// Gets access to the underlying `T` which represents this resource.
          pub fn get<T: GuestInstance>(&self) -> &T {
            let ptr = unsafe { &*self.as_ptr::<T>() };
            ptr.as_ref().unwrap()
          }

          /// Gets mutable access to the underlying `T` which represents this
          /// resource.
          pub fn get_mut<T: GuestInstance>(&mut self) -> &mut T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.as_mut().unwrap()
          }

          /// Consumes this resource and returns the underlying `T`.
          pub fn into_inner<T: GuestInstance>(self) -> T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.take().unwrap()
          }

          #[doc(hidden)]
          pub unsafe fn from_handle(handle: u32) -> Self {
            Self {
              handle: unsafe { _rt::Resource::from_handle(handle) },
            }
          }

          #[doc(hidden)]
          pub fn take_handle(&self) -> u32 {
            _rt::Resource::take_handle(&self.handle)
          }

          #[doc(hidden)]
          pub fn handle(&self) -> u32 {
            _rt::Resource::handle(&self.handle)
          }

          // It's theoretically possible to implement the `GuestInstance` trait twice
          // so guard against using it with two different types here.
          #[doc(hidden)]
          fn type_guard<T: 'static>() {
            use core::any::TypeId;
            static mut LAST_TYPE: Option<TypeId> = None;
            unsafe {
              assert!(!cfg!(target_feature = "atomics"));
              let id = TypeId::of::<T>();
              match LAST_TYPE {
                Some(ty) => assert!(ty == id, "cannot use two types with this resource type"),
                None => LAST_TYPE = Some(id),
              }
            }
          }

          #[doc(hidden)]
          pub unsafe fn dtor<T: 'static>(handle: *mut u8) {
            Self::type_guard::<T>();
            let _ = unsafe { _rt::Box::from_raw(handle as *mut _InstanceRep<T>) };
          }

          fn as_ptr<T: GuestInstance>(&self) -> *mut _InstanceRep<T> {
            Instance::type_guard::<T>();
            T::_resource_rep(self.handle()).cast()
          }
        }

        /// A borrowed version of [`Instance`] which represents a borrowed value
        /// with the lifetime `'a`.
        #[derive(Debug)]
        #[repr(transparent)]
        pub struct InstanceBorrow<'a> {
          rep: *mut u8,
          _marker: core::marker::PhantomData<&'a Instance>,
        }

        impl<'a> InstanceBorrow<'a>{
          #[doc(hidden)]
          pub unsafe fn lift(rep: usize) -> Self {
            Self {
              rep: rep as *mut u8,
              _marker: core::marker::PhantomData,
            }
          }

          /// Gets access to the underlying `T` in this resource.
          pub fn get<T: GuestInstance>(&self) -> &'a T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.as_ref().unwrap()
          }

          // NB: mutable access is not allowed due to the component model allowing
          // multiple borrows of the same resource.

          fn as_ptr<T: 'static>(&self) -> *mut _InstanceRep<T> {
            Instance::type_guard::<T>();
            self.rep.cast()
          }
        }
        

        unsafe impl _rt::WasmResource for Instance{
          #[inline]
          unsafe fn drop(_handle: u32) {
            
            #[cfg(target_arch = "wasm32")]
            #[link(wasm_import_module = "[export]ntx:runner/protocol-component")]
            unsafe extern "C" {
              #[link_name = "[resource-drop]instance"]
              fn drop(_: i32, );
            }

            #[cfg(not(target_arch = "wasm32"))]
            unsafe extern "C" fn drop(_: i32, ) { unreachable!() }
            
            unsafe { drop(_handle as i32); }
          }
        }
        
        #[doc(hidden)]
        #[allow(non_snake_case, unused_unsafe)]
        pub unsafe fn _export_init_cabi<T: Guest>(arg0: *mut u8,arg1: usize,arg2: *mut u8,arg3: usize,arg4: *mut u8,arg5: usize,arg6: *mut u8,arg7: usize,arg8: i32,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
        _rt::run_ctors_once();let result5 = {
          let len0 = arg1;
          let bytes0 = _rt::Vec::from_raw_parts(arg0.cast(), len0, len0);
          let len1 = arg3;
          let bytes1 = _rt::Vec::from_raw_parts(arg2.cast(), len1, len1);
          let base3 = arg4;
          let len3 = arg5;
          let mut result3 = _rt::Vec::with_capacity(len3);
          for i in 0..len3 {
            let base = base3.add(i * 1);
            let e3 = {
              let l2 = i32::from(*base.add(0).cast::<u8>());

              super::super::super::super::ntx::runner::types::PfCapability::empty() | super::super::super::super::ntx::runner::types::PfCapability::from_bits_retain(((l2 as u8) << 0) as _)
            };
            result3.push(e3);
          }
          _rt::cabi_dealloc(base3, len3 * 1, 1);
          let len4 = arg7;
          let bytes4 = _rt::Vec::from_raw_parts(arg6.cast(), len4, len4);
          T::init(super::super::super::super::ntx::runner::types::ProtocolInitCtx{
            pf_id: _rt::string_lift(bytes0),
            workflow_id: _rt::string_lift(bytes1),
            capabilities: result3,
            resource_dir: _rt::string_lift(bytes4),
            user_count: arg8 as u32,
          })
        };
        let ptr6 = (&raw mut _RET_AREA.0).cast::<u8>();
        match result5 {
          Ok(e) => { {
            *ptr6.add(0).cast::<u8>() = (0i32) as u8;
            *ptr6.add(::core::mem::size_of::<*const u8>()).cast::<i32>() = (e).take_handle() as i32;
          } },
          Err(e) => { {
            *ptr6.add(0).cast::<u8>() = (1i32) as u8;
            let super::super::super::super::ntx::runner::types::PfError{ kind:kind7, message:message7, } = e;
            *ptr6.add(::core::mem::size_of::<*const u8>()).cast::<u8>() = (kind7.clone() as i32) as u8;
            let vec8 = (message7.into_bytes()).into_boxed_slice();
            let ptr8 = vec8.as_ptr().cast::<u8>();
            let len8 = vec8.len();
            ::core::mem::forget(vec8);
            *ptr6.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len8;
            *ptr6.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr8.cast_mut();
          } },
        };ptr6
      } }
      #[doc(hidden)]
      #[allow(non_snake_case)]
      pub unsafe fn __post_return_init<T: Guest>(arg0: *mut u8,) { unsafe {
        let l0 = i32::from(*arg0.add(0).cast::<u8>());
        match l0 {
          0 => (),
          _ => {
            let l1 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l2 = *arg0.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
            _rt::cabi_dealloc(l1, l2, 1);
          },
        }
      } }
      #[doc(hidden)]
      #[allow(non_snake_case, unused_unsafe)]
      pub unsafe fn _export_run_action_cabi<T: Guest>(arg0: *mut u8,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
      _rt::run_ctors_once();let result38 = {
        let l0 = *arg0.add(0).cast::<i32>();
        let l1 = *arg0.add(8).cast::<*mut u8>();
        let l2 = *arg0.add(8+1*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let len3 = l2;
        let bytes3 = _rt::Vec::from_raw_parts(l1.cast(), len3, len3);
        let l4 = *arg0.add(8+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
        let l5 = *arg0.add(8+3*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let len6 = l5;
        let bytes6 = _rt::Vec::from_raw_parts(l4.cast(), len6, len6);
        let l7 = *arg0.add(8+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
        let l8 = *arg0.add(8+5*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let len9 = l8;
        let bytes9 = _rt::Vec::from_raw_parts(l7.cast(), len9, len9);
        let l10 = i32::from(*arg0.add(8+6*::core::mem::size_of::<*const u8>()).cast::<u8>());
        let l11 = i32::from(*arg0.add(9+6*::core::mem::size_of::<*const u8>()).cast::<u8>());
        let l12 = *arg0.add(8+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
        let l13 = *arg0.add(8+8*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let len14 = l13;
        let bytes14 = _rt::Vec::from_raw_parts(l12.cast(), len14, len14);
        let l15 = i32::from(*arg0.add(8+9*::core::mem::size_of::<*const u8>()).cast::<u8>());
        let l19 = *arg0.add(8+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
        let l20 = *arg0.add(8+13*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let len21 = l20;
        let bytes21 = _rt::Vec::from_raw_parts(l19.cast(), len21, len21);
        let l22 = i32::from(*arg0.add(8+14*::core::mem::size_of::<*const u8>()).cast::<u8>());
        let l28 = *arg0.add(32+14*::core::mem::size_of::<*const u8>()).cast::<i64>();
        let l29 = *arg0.add(40+14*::core::mem::size_of::<*const u8>()).cast::<i32>();
        let l30 = *arg0.add(40+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
        let l31 = *arg0.add(40+16*::core::mem::size_of::<*const u8>()).cast::<usize>();
        let base35 = l30;
        let len35 = l31;
        let mut result35 = _rt::Vec::with_capacity(len35);
        for i in 0..len35 {
          let base = base35.add(i * (2*::core::mem::size_of::<*const u8>()));
          let e35 = {
            let l32 = *base.add(0).cast::<*mut u8>();
            let l33 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len34 = l33;
            let bytes34 = _rt::Vec::from_raw_parts(l32.cast(), len34, len34);

            _rt::string_lift(bytes34)
          };
          result35.push(e35);
        }
        _rt::cabi_dealloc(base35, len35 * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
        let l36 = i32::from(*arg0.add(48+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
        T::run_action(InstanceBorrow::lift(l0 as u32 as usize), super::super::super::super::ntx::runner::types::ActionCtx{
          task_id: _rt::string_lift(bytes3),
          action_id: _rt::string_lift(bytes6),
          user_id: _rt::string_lift(bytes9),
          protocol: super::super::super::super::ntx::runner::types::ProtocolKind::_lift(l10 as u8),
          origin: super::super::super::super::ntx::runner::types::ActionOrigin::_lift(l11 as u8),
          payload: super::super::super::super::ntx::runner::types::PayloadRef{
            path: _rt::string_lift(bytes14),
            checksum: match l15 {
              0 => None,
              1 => {
                let e = {
                  let l16 = *arg0.add(8+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                  let l17 = *arg0.add(8+11*::core::mem::size_of::<*const u8>()).cast::<usize>();
                  let len18 = l17;
                  let bytes18 = _rt::Vec::from_raw_parts(l16.cast(), len18, len18);

                  _rt::string_lift(bytes18)
                };
                Some(e)
              }
              _ => _rt::invalid_enum_discriminant(),
            },
            format: _rt::string_lift(bytes21),
          },
          rate: match l22 {
            0 => None,
            1 => {
              let e = {
                let l23 = *arg0.add(12+14*::core::mem::size_of::<*const u8>()).cast::<i32>();
                let l24 = i32::from(*arg0.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>());
                let l26 = i32::from(*arg0.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>());

                super::super::super::super::ntx::runner::types::RateProfile{
                  bytes_per_tick: l23 as u32,
                  max_burst_bytes: match l24 {
                    0 => None,
                    1 => {
                      let e = {
                        let l25 = *arg0.add(20+14*::core::mem::size_of::<*const u8>()).cast::<i32>();

                        l25 as u32
                      };
                      Some(e)
                    }
                    _ => _rt::invalid_enum_discriminant(),
                  },
                  max_inflight: match l26 {
                    0 => None,
                    1 => {
                      let e = {
                        let l27 = *arg0.add(28+14*::core::mem::size_of::<*const u8>()).cast::<i32>();

                        l27 as u32
                      };
                      Some(e)
                    }
                    _ => _rt::invalid_enum_discriminant(),
                  },
                }
              };
              Some(e)
            }
            _ => _rt::invalid_enum_discriminant(),
          },
          tick: l28 as u64,
          attempt: l29 as u32,
          dependencies: result35,
          deadline_ns: match l36 {
            0 => None,
            1 => {
              let e = {
                let l37 = *arg0.add(56+16*::core::mem::size_of::<*const u8>()).cast::<i64>();

                l37 as u64
              };
              Some(e)
            }
            _ => _rt::invalid_enum_discriminant(),
          },
        })
      };
      _rt::cabi_dealloc(arg0, 64+16*::core::mem::size_of::<*const u8>(), 8);
      let ptr39 = (&raw mut _RET_AREA.0).cast::<u8>();
      match result38 {
        Ok(e) => { {
          *ptr39.add(0).cast::<u8>() = (0i32) as u8;
          let super::super::super::super::ntx::runner::types::ActionResult{ ctx:ctx40, phase:phase40, outcome:outcome40, progress:progress40, error_message:error_message40, } = e;
          let super::super::super::super::ntx::runner::types::ActionCtx{ task_id:task_id41, action_id:action_id41, user_id:user_id41, protocol:protocol41, origin:origin41, payload:payload41, rate:rate41, tick:tick41, attempt:attempt41, dependencies:dependencies41, deadline_ns:deadline_ns41, } = ctx40;
          let vec42 = (task_id41.into_bytes()).into_boxed_slice();
          let ptr42 = vec42.as_ptr().cast::<u8>();
          let len42 = vec42.len();
          ::core::mem::forget(vec42);
          *ptr39.add(8+1*::core::mem::size_of::<*const u8>()).cast::<usize>() = len42;
          *ptr39.add(8).cast::<*mut u8>() = ptr42.cast_mut();
          let vec43 = (action_id41.into_bytes()).into_boxed_slice();
          let ptr43 = vec43.as_ptr().cast::<u8>();
          let len43 = vec43.len();
          ::core::mem::forget(vec43);
          *ptr39.add(8+3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len43;
          *ptr39.add(8+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr43.cast_mut();
          let vec44 = (user_id41.into_bytes()).into_boxed_slice();
          let ptr44 = vec44.as_ptr().cast::<u8>();
          let len44 = vec44.len();
          ::core::mem::forget(vec44);
          *ptr39.add(8+5*::core::mem::size_of::<*const u8>()).cast::<usize>() = len44;
          *ptr39.add(8+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr44.cast_mut();
          *ptr39.add(8+6*::core::mem::size_of::<*const u8>()).cast::<u8>() = (protocol41.clone() as i32) as u8;
          *ptr39.add(9+6*::core::mem::size_of::<*const u8>()).cast::<u8>() = (origin41.clone() as i32) as u8;
          let super::super::super::super::ntx::runner::types::PayloadRef{ path:path45, checksum:checksum45, format:format45, } = payload41;
          let vec46 = (path45.into_bytes()).into_boxed_slice();
          let ptr46 = vec46.as_ptr().cast::<u8>();
          let len46 = vec46.len();
          ::core::mem::forget(vec46);
          *ptr39.add(8+8*::core::mem::size_of::<*const u8>()).cast::<usize>() = len46;
          *ptr39.add(8+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr46.cast_mut();
          match checksum45 {
            Some(e) => {
              *ptr39.add(8+9*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
              let vec47 = (e.into_bytes()).into_boxed_slice();
              let ptr47 = vec47.as_ptr().cast::<u8>();
              let len47 = vec47.len();
              ::core::mem::forget(vec47);
              *ptr39.add(8+11*::core::mem::size_of::<*const u8>()).cast::<usize>() = len47;
              *ptr39.add(8+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr47.cast_mut();
            },
            None => {
              {
                *ptr39.add(8+9*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
              }
            },
          };let vec48 = (format45.into_bytes()).into_boxed_slice();
          let ptr48 = vec48.as_ptr().cast::<u8>();
          let len48 = vec48.len();
          ::core::mem::forget(vec48);
          *ptr39.add(8+13*::core::mem::size_of::<*const u8>()).cast::<usize>() = len48;
          *ptr39.add(8+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr48.cast_mut();
          match rate41 {
            Some(e) => {
              *ptr39.add(8+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
              let super::super::super::super::ntx::runner::types::RateProfile{ bytes_per_tick:bytes_per_tick49, max_burst_bytes:max_burst_bytes49, max_inflight:max_inflight49, } = e;
              *ptr39.add(12+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(bytes_per_tick49);
              match max_burst_bytes49 {
                Some(e) => {
                  *ptr39.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                  *ptr39.add(20+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(e);
                },
                None => {
                  {
                    *ptr39.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                  }
                },
              };match max_inflight49 {
                Some(e) => {
                  *ptr39.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                  *ptr39.add(28+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(e);
                },
                None => {
                  {
                    *ptr39.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                  }
                },
              };},
              None => {
                {
                  *ptr39.add(8+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                }
              },
            };*ptr39.add(32+14*::core::mem::size_of::<*const u8>()).cast::<i64>() = _rt::as_i64(tick41);
            *ptr39.add(40+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(attempt41);
            let vec51 = dependencies41;
            let len51 = vec51.len();
            let layout51 = _rt::alloc::Layout::from_size_align(vec51.len() * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>()).unwrap();
            let (result51, _cleanup51) = wit_bindgen::rt::Cleanup::new(layout51);if let Some(cleanup) = _cleanup51 { cleanup.forget(); }
            for (i, e) in vec51.into_iter().enumerate() {
              let base = result51.add(i * (2*::core::mem::size_of::<*const u8>()));
              {
                let vec50 = (e.into_bytes()).into_boxed_slice();
                let ptr50 = vec50.as_ptr().cast::<u8>();
                let len50 = vec50.len();
                ::core::mem::forget(vec50);
                *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>() = len50;
                *base.add(0).cast::<*mut u8>() = ptr50.cast_mut();
              }
            }
            *ptr39.add(40+16*::core::mem::size_of::<*const u8>()).cast::<usize>() = len51;
            *ptr39.add(40+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = result51;
            match deadline_ns41 {
              Some(e) => {
                *ptr39.add(48+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                *ptr39.add(56+16*::core::mem::size_of::<*const u8>()).cast::<i64>() = _rt::as_i64(e);
              },
              None => {
                {
                  *ptr39.add(48+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                }
              },
            };*ptr39.add(64+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (phase40.clone() as i32) as u8;
            *ptr39.add(65+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (outcome40.clone() as i32) as u8;
            *ptr39.add(68+16*::core::mem::size_of::<*const u8>()).cast::<f32>() = _rt::as_f32(progress40);
            match error_message40 {
              Some(e) => {
                *ptr39.add(72+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                let vec52 = (e.into_bytes()).into_boxed_slice();
                let ptr52 = vec52.as_ptr().cast::<u8>();
                let len52 = vec52.len();
                ::core::mem::forget(vec52);
                *ptr39.add(72+18*::core::mem::size_of::<*const u8>()).cast::<usize>() = len52;
                *ptr39.add(72+17*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr52.cast_mut();
              },
              None => {
                {
                  *ptr39.add(72+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                }
              },
            };} },
            Err(e) => { {
              *ptr39.add(0).cast::<u8>() = (1i32) as u8;
              let super::super::super::super::ntx::runner::types::PfError{ kind:kind53, message:message53, } = e;
              *ptr39.add(8).cast::<u8>() = (kind53.clone() as i32) as u8;
              let vec54 = (message53.into_bytes()).into_boxed_slice();
              let ptr54 = vec54.as_ptr().cast::<u8>();
              let len54 = vec54.len();
              ::core::mem::forget(vec54);
              *ptr39.add(8+2*::core::mem::size_of::<*const u8>()).cast::<usize>() = len54;
              *ptr39.add(8+1*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr54.cast_mut();
            } },
          };ptr39
        } }
        #[doc(hidden)]
        #[allow(non_snake_case)]
        pub unsafe fn __post_return_run_action<T: Guest>(arg0: *mut u8,) { unsafe {
          let l0 = i32::from(*arg0.add(0).cast::<u8>());
          match l0 {
            0 => {
              let l1 = *arg0.add(8).cast::<*mut u8>();
              let l2 = *arg0.add(8+1*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l1, l2, 1);
              let l3 = *arg0.add(8+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l4 = *arg0.add(8+3*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l3, l4, 1);
              let l5 = *arg0.add(8+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l6 = *arg0.add(8+5*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l5, l6, 1);
              let l7 = *arg0.add(8+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l8 = *arg0.add(8+8*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l7, l8, 1);
              let l9 = i32::from(*arg0.add(8+9*::core::mem::size_of::<*const u8>()).cast::<u8>());
              match l9 {
                0 => (),
                _ => {
                  let l10 = *arg0.add(8+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                  let l11 = *arg0.add(8+11*::core::mem::size_of::<*const u8>()).cast::<usize>();
                  _rt::cabi_dealloc(l10, l11, 1);
                },
              }
              let l12 = *arg0.add(8+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l13 = *arg0.add(8+13*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l12, l13, 1);
              let l14 = *arg0.add(40+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l15 = *arg0.add(40+16*::core::mem::size_of::<*const u8>()).cast::<usize>();
              let base18 = l14;
              let len18 = l15;
              for i in 0..len18 {
                let base = base18.add(i * (2*::core::mem::size_of::<*const u8>()));
                {
                  let l16 = *base.add(0).cast::<*mut u8>();
                  let l17 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
                  _rt::cabi_dealloc(l16, l17, 1);
                }
              }
              _rt::cabi_dealloc(base18, len18 * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
              let l19 = i32::from(*arg0.add(72+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
              match l19 {
                0 => (),
                _ => {
                  let l20 = *arg0.add(72+17*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                  let l21 = *arg0.add(72+18*::core::mem::size_of::<*const u8>()).cast::<usize>();
                  _rt::cabi_dealloc(l20, l21, 1);
                },
              }
            },
            _ => {
              let l22 = *arg0.add(8+1*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l23 = *arg0.add(8+2*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l22, l23, 1);
            },
          }
        } }
        #[doc(hidden)]
        #[allow(non_snake_case, unused_unsafe)]
        pub unsafe fn _export_on_error_cabi<T: Guest>(arg0: i32,arg1: i32,arg2: *mut u8,arg3: usize,) { unsafe {#[cfg(target_arch="wasm32")]
        _rt::run_ctors_once();{
          let len0 = arg3;
          let bytes0 = _rt::Vec::from_raw_parts(arg2.cast(), len0, len0);
          T::on_error(InstanceBorrow::lift(arg0 as u32 as usize), super::super::super::super::ntx::runner::types::PfError{
            kind: super::super::super::super::ntx::runner::types::PfErrorKind::_lift(arg1 as u8),
            message: _rt::string_lift(bytes0),
          })
        };
      } }
      #[doc(hidden)]
      #[allow(non_snake_case, unused_unsafe)]
      pub unsafe fn _export_release_cabi<T: Guest>(arg0: i32,) { unsafe {#[cfg(target_arch="wasm32")]
      _rt::run_ctors_once();{
        T::release(Instance::from_handle(arg0 as u32))
      };
    } }
    pub trait Guest {
      type Instance: GuestInstance;
      /// Initialize internal protocol state. Called once per workflow deployment.
      #[allow(async_fn_in_trait)]
      fn init(ctx: ProtocolInitCtx,) -> Result<Instance,PfError>;
      /// Execute a single action as provided by Core/PF.
      #[allow(async_fn_in_trait)]
      fn run_action(inst: InstanceBorrow<'_>,action: ActionCtx,) -> Result<ActionResult,PfError>;
      /// Receive asynchronous error notifications originating from PF/Core.
      #[allow(async_fn_in_trait)]
      fn on_error(inst: InstanceBorrow<'_>,err: PfError,) -> ();
      /// Release all protocol-owned resources.
      #[allow(async_fn_in_trait)]
      fn release(inst: Instance,) -> ();
    }
    pub trait GuestInstance: 'static {

      #[doc(hidden)]
      unsafe fn _resource_new(val: *mut u8) -> u32
      where Self: Sized
      {
        
        #[cfg(target_arch = "wasm32")]
        #[link(wasm_import_module = "[export]ntx:runner/protocol-component")]
        unsafe extern "C" {
          #[link_name = "[resource-new]instance"]
          fn new(_: *mut u8, ) -> i32;
        }

        #[cfg(not(target_arch = "wasm32"))]
        unsafe extern "C" fn new(_: *mut u8, ) -> i32 { unreachable!() }
        
        unsafe { new(val) as u32 }
      }

      #[doc(hidden)]
      fn _resource_rep(handle: u32) -> *mut u8
      where Self: Sized
      {
        
        #[cfg(target_arch = "wasm32")]
        #[link(wasm_import_module = "[export]ntx:runner/protocol-component")]
        unsafe extern "C" {
          #[link_name = "[resource-rep]instance"]
          fn rep(_: i32, ) -> *mut u8;
        }

        #[cfg(not(target_arch = "wasm32"))]
        unsafe extern "C" fn rep(_: i32, ) -> *mut u8 { unreachable!() }
        
        unsafe { rep(handle as i32) }
      }

      
    }
    #[doc(hidden)]

    macro_rules! __export_ntx_runner_protocol_component_cabi{
      ($ty:ident with_types_in $($path_to_types:tt)*) => (const _: () = {

        #[unsafe(export_name = "ntx:runner/protocol-component#init")]
        unsafe extern "C" fn export_init(arg0: *mut u8,arg1: usize,arg2: *mut u8,arg3: usize,arg4: *mut u8,arg5: usize,arg6: *mut u8,arg7: usize,arg8: i32,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_init_cabi::<$ty>(arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/protocol-component#init")]
        unsafe extern "C" fn _post_return_init(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_init::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/protocol-component#run-action")]
        unsafe extern "C" fn export_run_action(arg0: *mut u8,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_run_action_cabi::<$ty>(arg0) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/protocol-component#run-action")]
        unsafe extern "C" fn _post_return_run_action(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_run_action::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/protocol-component#on-error")]
        unsafe extern "C" fn export_on_error(arg0: i32,arg1: i32,arg2: *mut u8,arg3: usize,) {
          unsafe { $($path_to_types)*::_export_on_error_cabi::<$ty>(arg0, arg1, arg2, arg3) }
        }
        #[unsafe(export_name = "ntx:runner/protocol-component#release")]
        unsafe extern "C" fn export_release(arg0: i32,) {
          unsafe { $($path_to_types)*::_export_release_cabi::<$ty>(arg0) }
        }

        const _: () = {
          #[doc(hidden)]
          #[unsafe(export_name = "ntx:runner/protocol-component#[dtor]instance")]
          #[allow(non_snake_case)]
          unsafe extern "C" fn dtor(rep: *mut u8) {
            unsafe {
              $($path_to_types)*::Instance::dtor::<
              <$ty as $($path_to_types)*::Guest>::Instance
              >(rep)
            }
          }
        };
        
      };);
    }
    #[doc(hidden)]
    pub(crate) use __export_ntx_runner_protocol_component_cabi;

    #[repr(align(8))]
    struct _RetArea([::core::mem::MaybeUninit::<u8>; 80+18*::core::mem::size_of::<*const u8>()]);
    static mut _RET_AREA: _RetArea = _RetArea([::core::mem::MaybeUninit::uninit(); 80+18*::core::mem::size_of::<*const u8>()]);

  }

}
}
}
mod _rt {
  #![allow(dead_code, clippy::all)]
  pub use alloc_crate::string::String;
  pub use alloc_crate::vec::Vec;


  use core::fmt;
  use core::marker;
  use core::sync::atomic::{AtomicU32, Ordering::Relaxed};

  /// A type which represents a component model resource, either imported or
  /// exported into this component.
  ///
  /// This is a low-level wrapper which handles the lifetime of the resource
  /// (namely this has a destructor). The `T` provided defines the component model
  /// intrinsics that this wrapper uses.
  ///
  /// One of the chief purposes of this type is to provide `Deref` implementations
  /// to access the underlying data when it is owned.
  ///
  /// This type is primarily used in generated code for exported and imported
  /// resources.
  #[repr(transparent)]
  pub struct Resource<T: WasmResource> {
    // NB: This would ideally be `u32` but it is not. The fact that this has
    // interior mutability is not exposed in the API of this type except for the
    // `take_handle` method which is supposed to in theory be private.
    //
    // This represents, almost all the time, a valid handle value. When it's
    // invalid it's stored as `u32::MAX`.
    handle: AtomicU32,
    _marker: marker::PhantomData<T>,
  }

  /// A trait which all wasm resources implement, namely providing the ability to
  /// drop a resource.
  ///
  /// This generally is implemented by generated code, not user-facing code.
  #[allow(clippy::missing_safety_doc)]
  pub unsafe trait WasmResource {
    /// Invokes the `[resource-drop]...` intrinsic.
    unsafe fn drop(handle: u32);
  }

  impl<T: WasmResource> Resource<T> {
    #[doc(hidden)]
    pub unsafe fn from_handle(handle: u32) -> Self {
      debug_assert!(handle != 0 && handle != u32::MAX);
      Self {
        handle: AtomicU32::new(handle),
        _marker: marker::PhantomData,
      }
    }

    /// Takes ownership of the handle owned by `resource`.
    ///
    /// Note that this ideally would be `into_handle` taking `Resource<T>` by
    /// ownership. The code generator does not enable that in all situations,
    /// unfortunately, so this is provided instead.
    ///
    /// Also note that `take_handle` is in theory only ever called on values
    /// owned by a generated function. For example a generated function might
    /// take `Resource<T>` as an argument but then call `take_handle` on a
    /// reference to that argument. In that sense the dynamic nature of
    /// `take_handle` should only be exposed internally to generated code, not
    /// to user code.
    #[doc(hidden)]
    pub fn take_handle(resource: &Resource<T>) -> u32 {
      resource.handle.swap(u32::MAX, Relaxed)
    }

    #[doc(hidden)]
    pub fn handle(resource: &Resource<T>) -> u32 {
      resource.handle.load(Relaxed)
    }
  }

  impl<T: WasmResource> fmt::Debug for Resource<T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
      f.debug_struct("Resource")
      .field("handle", &self.handle)
      .finish()
    }
  }

  impl<T: WasmResource> Drop for Resource<T> {
    fn drop(&mut self) {
      unsafe {
        match self.handle.load(Relaxed) {
          // If this handle was "taken" then don't do anything in the
          // destructor.
          u32::MAX => {}

          // ... but otherwise do actually destroy it with the imported
          // component model intrinsic as defined through `T`.
          other => T::drop(other),
        }
      }
    }
  }
  pub use alloc_crate::boxed::Box;

  #[cfg(target_arch = "wasm32")]
  pub fn run_ctors_once() {
    wit_bindgen::rt::run_ctors_once();
  }
  pub unsafe fn string_lift(bytes: Vec<u8>) -> String {
    if cfg!(debug_assertions) {
      String::from_utf8(bytes).unwrap()
    } else {
      unsafe { String::from_utf8_unchecked(bytes) }
    }
  }
  pub unsafe fn cabi_dealloc(ptr: *mut u8, size: usize, align: usize) {
    if size == 0 {
      return;
    }
    unsafe {
      let layout = alloc::Layout::from_size_align_unchecked(size, align);
      alloc::dealloc(ptr, layout);
    }
  }
  pub unsafe fn invalid_enum_discriminant<T>() -> T {
    if cfg!(debug_assertions) {
      panic!("invalid enum discriminant")
    } else {
      unsafe { core::hint::unreachable_unchecked() }
    }
  }
  
  pub fn as_i32<T: AsI32>(t: T) -> i32 {
    t.as_i32()
  }

  pub trait AsI32 {
    fn as_i32(self) -> i32;
  }

  impl<'a, T: Copy + AsI32> AsI32 for &'a T {
    fn as_i32(self) -> i32 {
      (*self).as_i32()
    }
  }
  
  impl AsI32 for i32 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u32 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for i16 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u16 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for i8 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u8 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for char {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for usize {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  pub fn as_i64<T: AsI64>(t: T) -> i64 {
    t.as_i64()
  }

  pub trait AsI64 {
    fn as_i64(self) -> i64;
  }

  impl<'a, T: Copy + AsI64> AsI64 for &'a T {
    fn as_i64(self) -> i64 {
      (*self).as_i64()
    }
  }
  
  impl AsI64 for i64 {
    #[inline]
    fn as_i64(self) -> i64 {
      self as i64
    }
  }
  
  impl AsI64 for u64 {
    #[inline]
    fn as_i64(self) -> i64 {
      self as i64
    }
  }
  pub use alloc_crate::alloc;

  pub fn as_f32<T: AsF32>(t: T) -> f32 {
    t.as_f32()
  }

  pub trait AsF32 {
    fn as_f32(self) -> f32;
  }

  impl<'a, T: Copy + AsF32> AsF32 for &'a T {
    fn as_f32(self) -> f32 {
      (*self).as_f32()
    }
  }
  
  impl AsF32 for f32 {
    #[inline]
    fn as_f32(self) -> f32 {
      self as f32
    }
  }
  extern crate alloc as alloc_crate;
}

/// Generates `#[unsafe(no_mangle)]` functions to export the specified type as
/// the root implementation of all generated traits.
///
/// For more information see the documentation of `wit_bindgen::generate!`.
///
/// ```rust
/// # macro_rules! export{ ($($t:tt)*) => (); }
/// # trait Guest {}
/// struct MyType;
///
/// impl Guest for MyType {
///     // ...
/// }
///
/// export!(MyType);
/// ```
#[allow(unused_macros)]
#[doc(hidden)]

macro_rules! __export_protocol_world_impl {
  ($ty:ident) => (self::export!($ty with_types_in self););
  ($ty:ident with_types_in $($path_to_types_root:tt)*) => (
  $($path_to_types_root)*::exports::ntx::runner::protocol_component::__export_ntx_runner_protocol_component_cabi!($ty with_types_in $($path_to_types_root)*::exports::ntx::runner::protocol_component);
  )
}
#[doc(inline)]
pub(crate) use __export_protocol_world_impl as export;

#[cfg(target_arch = "wasm32")]
#[unsafe(link_section = "component-type:wit-bindgen:0.48.0:ntx:runner:protocol-world:encoded world")]
#[doc(hidden)]
#[allow(clippy::octal_escapes)]
pub static __WIT_BINDGEN_COMPONENT_TYPE: [u8; 1798] = *b"\
\0asm\x0d\0\x01\0\0\x19\x16wit-component-encoding\x04\0\x07\x81\x0d\x01A\x02\x01\
A\x08\x01B3\x01s\x04\0\x07task-id\x03\0\0\x01s\x04\0\x07user-id\x03\0\x02\x01s\x04\
\0\x09action-id\x03\0\x04\x01m\x04\x04http\x03ftp\x09tcp-probe\x06custom\x04\0\x0d\
protocol-kind\x03\0\x06\x01m\x02\x0bhost-script\x11runtime-generated\x04\0\x0dac\
tion-origin\x03\0\x08\x01m\x06\x07pending\x07running\x07waiting\x08retrying\x09c\
ompleted\x06failed\x04\0\x0caction-phase\x03\0\x0a\x01m\x03\x07success\x07skippe\
d\x06failed\x04\0\x12action-result-kind\x03\0\x0c\x01m\x05\x0binvalid-ctx\x08cap\
acity\x02io\x07timeout\x08internal\x04\0\x14scheduler-error-kind\x03\0\x0e\x01m\x04\
\x0finvalid-request\x09throttled\x09not-found\x08internal\x04\0\x0dpf-error-kind\
\x03\0\x10\x01n\x06\x06logger\x05timer\x06socket\x0arate-guard\x08progress\x0aca\
ll-model\x04\0\x0dpf-capability\x03\0\x12\x01ky\x01r\x04\x0bworkflow-ids\x10tick\
-duration-msy\x0fmax-concurrencyy\x0cwarmup-ticks\x14\x04\0\x10scheduler-config\x03\
\0\x15\x01r\x03\x0ebytes-per-ticky\x0fmax-burst-bytes\x14\x0cmax-inflight\x14\x04\
\0\x0crate-profile\x03\0\x17\x01ks\x01r\x06\x07task-id\x01\x0bworkflow-ids\x08pr\
otocol\x07\x08priority}\x0ctemplate-ref\x19\x06origin\x09\x04\0\x09task-meta\x03\
\0\x1a\x01k\x7f\x01r\x03\x04hosts\x04port{\x03tls\x1c\x04\0\x08endpoint\x03\0\x1d\
\x01r\x03\x04paths\x08checksum\x19\x06formats\x04\0\x0bpayload-ref\x03\0\x1f\x01\
k\x18\x01p\x05\x01kw\x01r\x0b\x07task-id\x01\x09action-id\x05\x07user-id\x03\x08\
protocol\x07\x06origin\x09\x07payload\x20\x04rate!\x04tickw\x07attempty\x0cdepen\
dencies\"\x0bdeadline-ns#\x04\0\x0aaction-ctx\x03\0$\x01r\x05\x03ctx%\x05phase\x0b\
\x07outcome\x0d\x08progressv\x0derror-message\x19\x04\0\x0daction-result\x03\0&\x01\
r\x03\x07task-id\x01\x08accepted\x7f\x06reason\x19\x04\0\x0eenqueue-result\x03\0\
(\x01r\x02\x04kind\x0f\x07messages\x04\0\x0fscheduler-error\x03\0*\x01r\x02\x04k\
ind\x11\x07messages\x04\0\x08pf-error\x03\0,\x01p\x13\x01r\x05\x05pf-ids\x0bwork\
flow-ids\x0ccapabilities.\x0cresource-dirs\x0auser-county\x04\0\x11protocol-init\
-ctx\x03\0/\x01r\x03\x07user-id\x03\x09blob-paths\x0dupdated-at-nsw\x04\0\x10use\
r-store-entry\x03\01\x03\0\x10ntx:runner/types\x05\0\x02\x03\0\0\x11protocol-ini\
t-ctx\x02\x03\0\0\x0aaction-ctx\x02\x03\0\0\x0daction-result\x02\x03\0\0\x08pf-e\
rror\x01B\x15\x02\x03\x02\x01\x01\x04\0\x11protocol-init-ctx\x03\0\0\x02\x03\x02\
\x01\x02\x04\0\x0aaction-ctx\x03\0\x02\x02\x03\x02\x01\x03\x04\0\x0daction-resul\
t\x03\0\x04\x02\x03\x02\x01\x04\x04\0\x08pf-error\x03\0\x06\x04\0\x08instance\x03\
\x01\x01i\x08\x01j\x01\x09\x01\x07\x01@\x01\x03ctx\x01\0\x0a\x04\0\x04init\x01\x0b\
\x01h\x08\x01j\x01\x05\x01\x07\x01@\x02\x04inst\x0c\x06action\x03\0\x0d\x04\0\x0a\
run-action\x01\x0e\x01@\x02\x04inst\x0c\x03err\x07\x01\0\x04\0\x08on-error\x01\x0f\
\x01@\x01\x04inst\x09\x01\0\x04\0\x07release\x01\x10\x04\0\x1dntx:runner/protoco\
l-component\x05\x05\x04\0\x19ntx:runner/protocol-world\x04\0\x0b\x14\x01\0\x0epr\
otocol-world\x03\0\0\0G\x09producers\x01\x0cprocessed-by\x02\x0dwit-component\x07\
0.241.2\x10wit-bindgen-rust\x060.48.0";

#[inline(never)]
#[doc(hidden)]
pub fn __link_custom_section_describing_imports() {
  wit_bindgen::rt::maybe_link_cabi_realloc();
}

