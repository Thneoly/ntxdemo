// Generated by `wit-bindgen` 0.48.0. DO NOT EDIT!
// Options used:
#[allow(dead_code, clippy::all)]
pub mod ntx {
  pub mod runner {
    /// Common data structures shared across Core, ProtocolFrame, and Protocol definitions.
    #[allow(dead_code, async_fn_in_trait, unused_imports, clippy::all)]
    pub mod types {
      #[used]
      #[doc(hidden)]
      static __FORCE_SECTION_REF: fn() =
      super::super::super::__link_custom_section_describing_imports;
      
      use super::super::super::_rt;
      /// Stable identifier for a workflow task.
      pub type TaskId = _rt::String;
      /// Stable identifier for a single logical user.
      pub type UserId = _rt::String;
      /// Identifier for an action node within a task tree.
      pub type ActionId = _rt::String;
      /// Supported protocol flavors.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ProtocolKind {
        Http,
        Ftp,
        TcpProbe,
        Custom,
      }
      impl ::core::fmt::Debug for ProtocolKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ProtocolKind::Http => {
              f.debug_tuple("ProtocolKind::Http").finish()
            }
            ProtocolKind::Ftp => {
              f.debug_tuple("ProtocolKind::Ftp").finish()
            }
            ProtocolKind::TcpProbe => {
              f.debug_tuple("ProtocolKind::TcpProbe").finish()
            }
            ProtocolKind::Custom => {
              f.debug_tuple("ProtocolKind::Custom").finish()
            }
          }
        }
      }

      impl ProtocolKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ProtocolKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ProtocolKind::Http,
            1 => ProtocolKind::Ftp,
            2 => ProtocolKind::TcpProbe,
            3 => ProtocolKind::Custom,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Tracks whether an action originates from Host scripts or runtime extensions.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionOrigin {
        HostScript,
        RuntimeGenerated,
      }
      impl ::core::fmt::Debug for ActionOrigin {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionOrigin::HostScript => {
              f.debug_tuple("ActionOrigin::HostScript").finish()
            }
            ActionOrigin::RuntimeGenerated => {
              f.debug_tuple("ActionOrigin::RuntimeGenerated").finish()
            }
          }
        }
      }

      impl ActionOrigin{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionOrigin{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionOrigin::HostScript,
            1 => ActionOrigin::RuntimeGenerated,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Scheduler lifecycle markers for actions.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionPhase {
        Pending,
        Running,
        Waiting,
        Retrying,
        Completed,
        Failed,
      }
      impl ::core::fmt::Debug for ActionPhase {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionPhase::Pending => {
              f.debug_tuple("ActionPhase::Pending").finish()
            }
            ActionPhase::Running => {
              f.debug_tuple("ActionPhase::Running").finish()
            }
            ActionPhase::Waiting => {
              f.debug_tuple("ActionPhase::Waiting").finish()
            }
            ActionPhase::Retrying => {
              f.debug_tuple("ActionPhase::Retrying").finish()
            }
            ActionPhase::Completed => {
              f.debug_tuple("ActionPhase::Completed").finish()
            }
            ActionPhase::Failed => {
              f.debug_tuple("ActionPhase::Failed").finish()
            }
          }
        }
      }

      impl ActionPhase{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionPhase{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionPhase::Pending,
            1 => ActionPhase::Running,
            2 => ActionPhase::Waiting,
            3 => ActionPhase::Retrying,
            4 => ActionPhase::Completed,
            5 => ActionPhase::Failed,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Result classification produced by Protocol implementations.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum ActionResultKind {
        Success,
        Skipped,
        Failed,
      }
      impl ::core::fmt::Debug for ActionResultKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            ActionResultKind::Success => {
              f.debug_tuple("ActionResultKind::Success").finish()
            }
            ActionResultKind::Skipped => {
              f.debug_tuple("ActionResultKind::Skipped").finish()
            }
            ActionResultKind::Failed => {
              f.debug_tuple("ActionResultKind::Failed").finish()
            }
          }
        }
      }

      impl ActionResultKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> ActionResultKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => ActionResultKind::Success,
            1 => ActionResultKind::Skipped,
            2 => ActionResultKind::Failed,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// High-level errors surfaced by the scheduler.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum SchedulerErrorKind {
        InvalidCtx,
        Capacity,
        Io,
        Timeout,
        Internal,
      }
      impl ::core::fmt::Debug for SchedulerErrorKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            SchedulerErrorKind::InvalidCtx => {
              f.debug_tuple("SchedulerErrorKind::InvalidCtx").finish()
            }
            SchedulerErrorKind::Capacity => {
              f.debug_tuple("SchedulerErrorKind::Capacity").finish()
            }
            SchedulerErrorKind::Io => {
              f.debug_tuple("SchedulerErrorKind::Io").finish()
            }
            SchedulerErrorKind::Timeout => {
              f.debug_tuple("SchedulerErrorKind::Timeout").finish()
            }
            SchedulerErrorKind::Internal => {
              f.debug_tuple("SchedulerErrorKind::Internal").finish()
            }
          }
        }
      }

      impl SchedulerErrorKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> SchedulerErrorKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => SchedulerErrorKind::InvalidCtx,
            1 => SchedulerErrorKind::Capacity,
            2 => SchedulerErrorKind::Io,
            3 => SchedulerErrorKind::Timeout,
            4 => SchedulerErrorKind::Internal,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      /// Errors emitted by ProtocolFrame services.
      #[repr(u8)]
      #[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd)]
      pub enum PfErrorKind {
        InvalidRequest,
        Throttled,
        NotFound,
        Internal,
      }
      impl ::core::fmt::Debug for PfErrorKind {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          match self {
            PfErrorKind::InvalidRequest => {
              f.debug_tuple("PfErrorKind::InvalidRequest").finish()
            }
            PfErrorKind::Throttled => {
              f.debug_tuple("PfErrorKind::Throttled").finish()
            }
            PfErrorKind::NotFound => {
              f.debug_tuple("PfErrorKind::NotFound").finish()
            }
            PfErrorKind::Internal => {
              f.debug_tuple("PfErrorKind::Internal").finish()
            }
          }
        }
      }

      impl PfErrorKind{
        #[doc(hidden)]
        pub unsafe fn _lift(val: u8) -> PfErrorKind{
          if !cfg!(debug_assertions) {
            return unsafe { ::core::mem::transmute(val) };
          }

          match val {
            0 => PfErrorKind::InvalidRequest,
            1 => PfErrorKind::Throttled,
            2 => PfErrorKind::NotFound,
            3 => PfErrorKind::Internal,

            _ => panic!("invalid enum discriminant"),
          }
        }
      }

      wit_bindgen::rt::bitflags::bitflags! {
        /// Capability flags advertised by ProtocolFrame to Protocol implementations.
        #[derive(PartialEq, Eq, PartialOrd, Ord, Hash, Debug, Clone, Copy)]
        pub struct PfCapability: u8 {
          const LOGGER = 1 << 0;
          const TIMER = 1 << 1;
          const SOCKET = 1 << 2;
          const RATE_GUARD = 1 << 3;
          const PROGRESS = 1 << 4;
          const CALL_MODEL = 1 << 5;
        }
      }
      /// Configures scheduler invariants for a workflow.
      #[derive(Clone)]
      pub struct SchedulerConfig {
        pub workflow_id: _rt::String,
        pub tick_duration_ms: u32,
        pub max_concurrency: u32,
        pub warmup_ticks: Option<u32>,
      }
      impl ::core::fmt::Debug for SchedulerConfig {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("SchedulerConfig").field("workflow-id", &self.workflow_id).field("tick-duration-ms", &self.tick_duration_ms).field("max-concurrency", &self.max_concurrency).field("warmup-ticks", &self.warmup_ticks).finish()
        }
      }
      /// Describes the rate settings Core applies per action.
      #[repr(C)]
      #[derive(Clone, Copy)]
      pub struct RateProfile {
        pub bytes_per_tick: u32,
        pub max_burst_bytes: Option<u32>,
        pub max_inflight: Option<u32>,
      }
      impl ::core::fmt::Debug for RateProfile {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("RateProfile").field("bytes-per-tick", &self.bytes_per_tick).field("max-burst-bytes", &self.max_burst_bytes).field("max-inflight", &self.max_inflight).finish()
        }
      }
      /// Canonical metadata for a task registered with the scheduler.
      #[derive(Clone)]
      pub struct TaskMeta {
        pub task_id: TaskId,
        pub workflow_id: _rt::String,
        pub protocol: ProtocolKind,
        pub priority: u8,
        pub template_ref: Option<_rt::String>,
        pub origin: ActionOrigin,
      }
      impl ::core::fmt::Debug for TaskMeta {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("TaskMeta").field("task-id", &self.task_id).field("workflow-id", &self.workflow_id).field("protocol", &self.protocol).field("priority", &self.priority).field("template-ref", &self.template_ref).field("origin", &self.origin).finish()
        }
      }
      /// Network endpoint definition reused by Core libs.
      #[derive(Clone)]
      pub struct Endpoint {
        pub host: _rt::String,
        pub port: u16,
        pub tls: Option<bool>,
      }
      impl ::core::fmt::Debug for Endpoint {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("Endpoint").field("host", &self.host).field("port", &self.port).field("tls", &self.tls).finish()
        }
      }
      /// Serialized payload description Core hands to Protocol.
      #[derive(Clone)]
      pub struct PayloadRef {
        pub path: _rt::String,
        pub checksum: Option<_rt::String>,
        pub format: _rt::String,
      }
      impl ::core::fmt::Debug for PayloadRef {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("PayloadRef").field("path", &self.path).field("checksum", &self.checksum).field("format", &self.format).finish()
        }
      }
      /// Fully hydrated action context that Scheduler/PF deliver to Protocol.
      #[derive(Clone)]
      pub struct ActionCtx {
        pub task_id: TaskId,
        pub action_id: ActionId,
        pub user_id: UserId,
        pub protocol: ProtocolKind,
        pub origin: ActionOrigin,
        pub payload: PayloadRef,
        pub rate: Option<RateProfile>,
        pub tick: u64,
        pub attempt: u32,
        pub dependencies: _rt::Vec::<ActionId>,
        pub deadline_ns: Option<u64>,
      }
      impl ::core::fmt::Debug for ActionCtx {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ActionCtx").field("task-id", &self.task_id).field("action-id", &self.action_id).field("user-id", &self.user_id).field("protocol", &self.protocol).field("origin", &self.origin).field("payload", &self.payload).field("rate", &self.rate).field("tick", &self.tick).field("attempt", &self.attempt).field("dependencies", &self.dependencies).field("deadline-ns", &self.deadline_ns).finish()
        }
      }
      /// Outcome reported by Protocol (via PF) back to Core.
      #[derive(Clone)]
      pub struct ActionResult {
        pub ctx: ActionCtx,
        pub phase: ActionPhase,
        pub outcome: ActionResultKind,
        pub progress: f32,
        pub error_message: Option<_rt::String>,
      }
      impl ::core::fmt::Debug for ActionResult {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ActionResult").field("ctx", &self.ctx).field("phase", &self.phase).field("outcome", &self.outcome).field("progress", &self.progress).field("error-message", &self.error_message).finish()
        }
      }
      /// Scheduler response when enqueuing runtime tasks.
      #[derive(Clone)]
      pub struct EnqueueResult {
        pub task_id: TaskId,
        pub accepted: bool,
        pub reason: Option<_rt::String>,
      }
      impl ::core::fmt::Debug for EnqueueResult {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("EnqueueResult").field("task-id", &self.task_id).field("accepted", &self.accepted).field("reason", &self.reason).finish()
        }
      }
      /// Canonical scheduler error container.
      #[derive(Clone)]
      pub struct SchedulerError {
        pub kind: SchedulerErrorKind,
        pub message: _rt::String,
      }
      impl ::core::fmt::Debug for SchedulerError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("SchedulerError").field("kind", &self.kind).field("message", &self.message).finish()
        }
      }
      impl ::core::fmt::Display for SchedulerError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          write!(f, "{:?}", self)
        }
      }
      impl ::core::error::Error for SchedulerError {}
      /// ProtocolFrame level errors.
      #[derive(Clone)]
      pub struct PfError {
        pub kind: PfErrorKind,
        pub message: _rt::String,
      }
      impl ::core::fmt::Debug for PfError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("PfError").field("kind", &self.kind).field("message", &self.message).finish()
        }
      }
      impl ::core::fmt::Display for PfError {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          write!(f, "{:?}", self)
        }
      }
      impl ::core::error::Error for PfError {}
      /// Metadata used when ProtocolFrame hands runtime context to Protocol.
      #[derive(Clone)]
      pub struct ProtocolInitCtx {
        pub pf_id: _rt::String,
        pub workflow_id: _rt::String,
        pub capabilities: _rt::Vec::<PfCapability>,
        pub resource_dir: _rt::String,
        pub user_count: u32,
      }
      impl ::core::fmt::Debug for ProtocolInitCtx {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("ProtocolInitCtx").field("pf-id", &self.pf_id).field("workflow-id", &self.workflow_id).field("capabilities", &self.capabilities).field("resource-dir", &self.resource_dir).field("user-count", &self.user_count).finish()
        }
      }
      /// Describes the storage slots PF can persist for each user.
      #[derive(Clone)]
      pub struct UserStoreEntry {
        pub user_id: UserId,
        pub blob_path: _rt::String,
        pub updated_at_ns: u64,
      }
      impl ::core::fmt::Debug for UserStoreEntry {
        fn fmt(&self, f: &mut ::core::fmt::Formatter<'_>) -> ::core::fmt::Result {
          f.debug_struct("UserStoreEntry").field("user-id", &self.user_id).field("blob-path", &self.blob_path).field("updated-at-ns", &self.updated_at_ns).finish()
        }
      }

    }

  }
}
#[allow(dead_code, clippy::all)]
pub mod exports {
  pub mod ntx {
    pub mod runner {

      #[allow(dead_code, async_fn_in_trait, unused_imports, clippy::all)]
      pub mod core_scheduler {
        #[used]
        #[doc(hidden)]
        static __FORCE_SECTION_REF: fn() =
        super::super::super::super::__link_custom_section_describing_imports;
        
        use super::super::super::super::_rt;
        pub type SchedulerConfig = super::super::super::super::ntx::runner::types::SchedulerConfig;
        pub type TaskMeta = super::super::super::super::ntx::runner::types::TaskMeta;
        pub type ActionCtx = super::super::super::super::ntx::runner::types::ActionCtx;
        pub type ActionResult = super::super::super::super::ntx::runner::types::ActionResult;
        pub type EnqueueResult = super::super::super::super::ntx::runner::types::EnqueueResult;
        pub type SchedulerError = super::super::super::super::ntx::runner::types::SchedulerError;

        #[derive(Debug)]
        #[repr(transparent)]
        pub struct Instance{
          handle: _rt::Resource<Instance>,
        }

        type _InstanceRep<T> = Option<T>;

        impl Instance{
          /// Creates a new resource from the specified representation.
          ///
          /// This function will create a new resource handle by moving `val` onto
          /// the heap and then passing that heap pointer to the component model to
          /// create a handle. The owned handle is then returned as `Instance`.
          pub fn new<T: GuestInstance>(val: T) -> Self {
            Self::type_guard::<T>();
            let val: _InstanceRep<T> = Some(val);
            let ptr: *mut _InstanceRep<T> =
            _rt::Box::into_raw(_rt::Box::new(val));
            unsafe {
              Self::from_handle(T::_resource_new(ptr.cast()))
            }
          }

          /// Gets access to the underlying `T` which represents this resource.
          pub fn get<T: GuestInstance>(&self) -> &T {
            let ptr = unsafe { &*self.as_ptr::<T>() };
            ptr.as_ref().unwrap()
          }

          /// Gets mutable access to the underlying `T` which represents this
          /// resource.
          pub fn get_mut<T: GuestInstance>(&mut self) -> &mut T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.as_mut().unwrap()
          }

          /// Consumes this resource and returns the underlying `T`.
          pub fn into_inner<T: GuestInstance>(self) -> T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.take().unwrap()
          }

          #[doc(hidden)]
          pub unsafe fn from_handle(handle: u32) -> Self {
            Self {
              handle: unsafe { _rt::Resource::from_handle(handle) },
            }
          }

          #[doc(hidden)]
          pub fn take_handle(&self) -> u32 {
            _rt::Resource::take_handle(&self.handle)
          }

          #[doc(hidden)]
          pub fn handle(&self) -> u32 {
            _rt::Resource::handle(&self.handle)
          }

          // It's theoretically possible to implement the `GuestInstance` trait twice
          // so guard against using it with two different types here.
          #[doc(hidden)]
          fn type_guard<T: 'static>() {
            use core::any::TypeId;
            static mut LAST_TYPE: Option<TypeId> = None;
            unsafe {
              assert!(!cfg!(target_feature = "atomics"));
              let id = TypeId::of::<T>();
              match LAST_TYPE {
                Some(ty) => assert!(ty == id, "cannot use two types with this resource type"),
                None => LAST_TYPE = Some(id),
              }
            }
          }

          #[doc(hidden)]
          pub unsafe fn dtor<T: 'static>(handle: *mut u8) {
            Self::type_guard::<T>();
            let _ = unsafe { _rt::Box::from_raw(handle as *mut _InstanceRep<T>) };
          }

          fn as_ptr<T: GuestInstance>(&self) -> *mut _InstanceRep<T> {
            Instance::type_guard::<T>();
            T::_resource_rep(self.handle()).cast()
          }
        }

        /// A borrowed version of [`Instance`] which represents a borrowed value
        /// with the lifetime `'a`.
        #[derive(Debug)]
        #[repr(transparent)]
        pub struct InstanceBorrow<'a> {
          rep: *mut u8,
          _marker: core::marker::PhantomData<&'a Instance>,
        }

        impl<'a> InstanceBorrow<'a>{
          #[doc(hidden)]
          pub unsafe fn lift(rep: usize) -> Self {
            Self {
              rep: rep as *mut u8,
              _marker: core::marker::PhantomData,
            }
          }

          /// Gets access to the underlying `T` in this resource.
          pub fn get<T: GuestInstance>(&self) -> &'a T {
            let ptr = unsafe { &mut *self.as_ptr::<T>() };
            ptr.as_ref().unwrap()
          }

          // NB: mutable access is not allowed due to the component model allowing
          // multiple borrows of the same resource.

          fn as_ptr<T: 'static>(&self) -> *mut _InstanceRep<T> {
            Instance::type_guard::<T>();
            self.rep.cast()
          }
        }
        

        unsafe impl _rt::WasmResource for Instance{
          #[inline]
          unsafe fn drop(_handle: u32) {
            
            #[cfg(target_arch = "wasm32")]
            #[link(wasm_import_module = "[export]ntx:runner/core-scheduler")]
            unsafe extern "C" {
              #[link_name = "[resource-drop]instance"]
              fn drop(_: i32, );
            }

            #[cfg(not(target_arch = "wasm32"))]
            unsafe extern "C" fn drop(_: i32, ) { unreachable!() }
            
            unsafe { drop(_handle as i32); }
          }
        }
        
        #[doc(hidden)]
        #[allow(non_snake_case, unused_unsafe)]
        pub unsafe fn _export_init_cabi<T: Guest>(arg0: *mut u8,arg1: usize,arg2: i32,arg3: i32,arg4: i32,arg5: i32,arg6: *mut u8,arg7: usize,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
        _rt::run_ctors_once();let result15 = {
          let len0 = arg1;
          let bytes0 = _rt::Vec::from_raw_parts(arg0.cast(), len0, len0);
          let base14 = arg6;
          let len14 = arg7;
          let mut result14 = _rt::Vec::with_capacity(len14);
          for i in 0..len14 {
            let base = base14.add(i * (9*::core::mem::size_of::<*const u8>()));
            let e14 = {
              let l1 = *base.add(0).cast::<*mut u8>();
              let l2 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
              let len3 = l2;
              let bytes3 = _rt::Vec::from_raw_parts(l1.cast(), len3, len3);
              let l4 = *base.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l5 = *base.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
              let len6 = l5;
              let bytes6 = _rt::Vec::from_raw_parts(l4.cast(), len6, len6);
              let l7 = i32::from(*base.add(4*::core::mem::size_of::<*const u8>()).cast::<u8>());
              let l8 = i32::from(*base.add(1+4*::core::mem::size_of::<*const u8>()).cast::<u8>());
              let l9 = i32::from(*base.add(5*::core::mem::size_of::<*const u8>()).cast::<u8>());
              let l13 = i32::from(*base.add(8*::core::mem::size_of::<*const u8>()).cast::<u8>());

              super::super::super::super::ntx::runner::types::TaskMeta{
                task_id: _rt::string_lift(bytes3),
                workflow_id: _rt::string_lift(bytes6),
                protocol: super::super::super::super::ntx::runner::types::ProtocolKind::_lift(l7 as u8),
                priority: l8 as u8,
                template_ref: match l9 {
                  0 => None,
                  1 => {
                    let e = {
                      let l10 = *base.add(6*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                      let l11 = *base.add(7*::core::mem::size_of::<*const u8>()).cast::<usize>();
                      let len12 = l11;
                      let bytes12 = _rt::Vec::from_raw_parts(l10.cast(), len12, len12);

                      _rt::string_lift(bytes12)
                    };
                    Some(e)
                  }
                  _ => _rt::invalid_enum_discriminant(),
                },
                origin: super::super::super::super::ntx::runner::types::ActionOrigin::_lift(l13 as u8),
              }
            };
            result14.push(e14);
          }
          _rt::cabi_dealloc(base14, len14 * (9*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
          T::init(super::super::super::super::ntx::runner::types::SchedulerConfig{
            workflow_id: _rt::string_lift(bytes0),
            tick_duration_ms: arg2 as u32,
            max_concurrency: arg3 as u32,
            warmup_ticks: match arg4 {
              0 => None,
              1 => {
                let e = arg5 as u32;
                Some(e)
              }
              _ => _rt::invalid_enum_discriminant(),
            },
          }, result14)
        };
        let ptr16 = (&raw mut _RET_AREA.0).cast::<u8>();
        match result15 {
          Ok(e) => { {
            *ptr16.add(0).cast::<u8>() = (0i32) as u8;
            *ptr16.add(::core::mem::size_of::<*const u8>()).cast::<i32>() = (e).take_handle() as i32;
          } },
          Err(e) => { {
            *ptr16.add(0).cast::<u8>() = (1i32) as u8;
            let super::super::super::super::ntx::runner::types::SchedulerError{ kind:kind17, message:message17, } = e;
            *ptr16.add(::core::mem::size_of::<*const u8>()).cast::<u8>() = (kind17.clone() as i32) as u8;
            let vec18 = (message17.into_bytes()).into_boxed_slice();
            let ptr18 = vec18.as_ptr().cast::<u8>();
            let len18 = vec18.len();
            ::core::mem::forget(vec18);
            *ptr16.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len18;
            *ptr16.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr18.cast_mut();
          } },
        };ptr16
      } }
      #[doc(hidden)]
      #[allow(non_snake_case)]
      pub unsafe fn __post_return_init<T: Guest>(arg0: *mut u8,) { unsafe {
        let l0 = i32::from(*arg0.add(0).cast::<u8>());
        match l0 {
          0 => (),
          _ => {
            let l1 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l2 = *arg0.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
            _rt::cabi_dealloc(l1, l2, 1);
          },
        }
      } }
      #[doc(hidden)]
      #[allow(non_snake_case, unused_unsafe)]
      pub unsafe fn _export_poll_action_cabi<T: Guest>(arg0: i32,arg1: i32,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
      _rt::run_ctors_once();let result0 = {
        T::poll_action(InstanceBorrow::lift(arg0 as u32 as usize), arg1 as u32)
      };
      let ptr1 = (&raw mut _RET_AREA.0).cast::<u8>();
      match result0 {
        Ok(e) => { {
          *ptr1.add(0).cast::<u8>() = (0i32) as u8;
          match e {
            Some(e) => {
              *ptr1.add(8).cast::<u8>() = (1i32) as u8;
              let super::super::super::super::ntx::runner::types::ActionCtx{ task_id:task_id2, action_id:action_id2, user_id:user_id2, protocol:protocol2, origin:origin2, payload:payload2, rate:rate2, tick:tick2, attempt:attempt2, dependencies:dependencies2, deadline_ns:deadline_ns2, } = e;
              let vec3 = (task_id2.into_bytes()).into_boxed_slice();
              let ptr3 = vec3.as_ptr().cast::<u8>();
              let len3 = vec3.len();
              ::core::mem::forget(vec3);
              *ptr1.add(16+1*::core::mem::size_of::<*const u8>()).cast::<usize>() = len3;
              *ptr1.add(16).cast::<*mut u8>() = ptr3.cast_mut();
              let vec4 = (action_id2.into_bytes()).into_boxed_slice();
              let ptr4 = vec4.as_ptr().cast::<u8>();
              let len4 = vec4.len();
              ::core::mem::forget(vec4);
              *ptr1.add(16+3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len4;
              *ptr1.add(16+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr4.cast_mut();
              let vec5 = (user_id2.into_bytes()).into_boxed_slice();
              let ptr5 = vec5.as_ptr().cast::<u8>();
              let len5 = vec5.len();
              ::core::mem::forget(vec5);
              *ptr1.add(16+5*::core::mem::size_of::<*const u8>()).cast::<usize>() = len5;
              *ptr1.add(16+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr5.cast_mut();
              *ptr1.add(16+6*::core::mem::size_of::<*const u8>()).cast::<u8>() = (protocol2.clone() as i32) as u8;
              *ptr1.add(17+6*::core::mem::size_of::<*const u8>()).cast::<u8>() = (origin2.clone() as i32) as u8;
              let super::super::super::super::ntx::runner::types::PayloadRef{ path:path6, checksum:checksum6, format:format6, } = payload2;
              let vec7 = (path6.into_bytes()).into_boxed_slice();
              let ptr7 = vec7.as_ptr().cast::<u8>();
              let len7 = vec7.len();
              ::core::mem::forget(vec7);
              *ptr1.add(16+8*::core::mem::size_of::<*const u8>()).cast::<usize>() = len7;
              *ptr1.add(16+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr7.cast_mut();
              match checksum6 {
                Some(e) => {
                  *ptr1.add(16+9*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                  let vec8 = (e.into_bytes()).into_boxed_slice();
                  let ptr8 = vec8.as_ptr().cast::<u8>();
                  let len8 = vec8.len();
                  ::core::mem::forget(vec8);
                  *ptr1.add(16+11*::core::mem::size_of::<*const u8>()).cast::<usize>() = len8;
                  *ptr1.add(16+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr8.cast_mut();
                },
                None => {
                  {
                    *ptr1.add(16+9*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                  }
                },
              };let vec9 = (format6.into_bytes()).into_boxed_slice();
              let ptr9 = vec9.as_ptr().cast::<u8>();
              let len9 = vec9.len();
              ::core::mem::forget(vec9);
              *ptr1.add(16+13*::core::mem::size_of::<*const u8>()).cast::<usize>() = len9;
              *ptr1.add(16+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr9.cast_mut();
              match rate2 {
                Some(e) => {
                  *ptr1.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                  let super::super::super::super::ntx::runner::types::RateProfile{ bytes_per_tick:bytes_per_tick10, max_burst_bytes:max_burst_bytes10, max_inflight:max_inflight10, } = e;
                  *ptr1.add(20+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(bytes_per_tick10);
                  match max_burst_bytes10 {
                    Some(e) => {
                      *ptr1.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                      *ptr1.add(28+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(e);
                    },
                    None => {
                      {
                        *ptr1.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                      }
                    },
                  };match max_inflight10 {
                    Some(e) => {
                      *ptr1.add(32+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                      *ptr1.add(36+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(e);
                    },
                    None => {
                      {
                        *ptr1.add(32+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                      }
                    },
                  };},
                  None => {
                    {
                      *ptr1.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                    }
                  },
                };*ptr1.add(40+14*::core::mem::size_of::<*const u8>()).cast::<i64>() = _rt::as_i64(tick2);
                *ptr1.add(48+14*::core::mem::size_of::<*const u8>()).cast::<i32>() = _rt::as_i32(attempt2);
                let vec12 = dependencies2;
                let len12 = vec12.len();
                let layout12 = _rt::alloc::Layout::from_size_align(vec12.len() * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>()).unwrap();
                let (result12, _cleanup12) = wit_bindgen::rt::Cleanup::new(layout12);if let Some(cleanup) = _cleanup12 { cleanup.forget(); }
                for (i, e) in vec12.into_iter().enumerate() {
                  let base = result12.add(i * (2*::core::mem::size_of::<*const u8>()));
                  {
                    let vec11 = (e.into_bytes()).into_boxed_slice();
                    let ptr11 = vec11.as_ptr().cast::<u8>();
                    let len11 = vec11.len();
                    ::core::mem::forget(vec11);
                    *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>() = len11;
                    *base.add(0).cast::<*mut u8>() = ptr11.cast_mut();
                  }
                }
                *ptr1.add(48+16*::core::mem::size_of::<*const u8>()).cast::<usize>() = len12;
                *ptr1.add(48+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = result12;
                match deadline_ns2 {
                  Some(e) => {
                    *ptr1.add(56+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                    *ptr1.add(64+16*::core::mem::size_of::<*const u8>()).cast::<i64>() = _rt::as_i64(e);
                  },
                  None => {
                    {
                      *ptr1.add(56+16*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                    }
                  },
                };},
                None => {
                  {
                    *ptr1.add(8).cast::<u8>() = (0i32) as u8;
                  }
                },
              };} },
              Err(e) => { {
                *ptr1.add(0).cast::<u8>() = (1i32) as u8;
                let super::super::super::super::ntx::runner::types::SchedulerError{ kind:kind13, message:message13, } = e;
                *ptr1.add(8).cast::<u8>() = (kind13.clone() as i32) as u8;
                let vec14 = (message13.into_bytes()).into_boxed_slice();
                let ptr14 = vec14.as_ptr().cast::<u8>();
                let len14 = vec14.len();
                ::core::mem::forget(vec14);
                *ptr1.add(8+2*::core::mem::size_of::<*const u8>()).cast::<usize>() = len14;
                *ptr1.add(8+1*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr14.cast_mut();
              } },
            };ptr1
          } }
          #[doc(hidden)]
          #[allow(non_snake_case)]
          pub unsafe fn __post_return_poll_action<T: Guest>(arg0: *mut u8,) { unsafe {
            let l0 = i32::from(*arg0.add(0).cast::<u8>());
            match l0 {
              0 => {
                let l1 = i32::from(*arg0.add(8).cast::<u8>());
                match l1 {
                  0 => (),
                  _ => {
                    let l2 = *arg0.add(16).cast::<*mut u8>();
                    let l3 = *arg0.add(16+1*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    _rt::cabi_dealloc(l2, l3, 1);
                    let l4 = *arg0.add(16+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l5 = *arg0.add(16+3*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    _rt::cabi_dealloc(l4, l5, 1);
                    let l6 = *arg0.add(16+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l7 = *arg0.add(16+5*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    _rt::cabi_dealloc(l6, l7, 1);
                    let l8 = *arg0.add(16+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l9 = *arg0.add(16+8*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    _rt::cabi_dealloc(l8, l9, 1);
                    let l10 = i32::from(*arg0.add(16+9*::core::mem::size_of::<*const u8>()).cast::<u8>());
                    match l10 {
                      0 => (),
                      _ => {
                        let l11 = *arg0.add(16+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                        let l12 = *arg0.add(16+11*::core::mem::size_of::<*const u8>()).cast::<usize>();
                        _rt::cabi_dealloc(l11, l12, 1);
                      },
                    }
                    let l13 = *arg0.add(16+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l14 = *arg0.add(16+13*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    _rt::cabi_dealloc(l13, l14, 1);
                    let l15 = *arg0.add(48+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l16 = *arg0.add(48+16*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    let base19 = l15;
                    let len19 = l16;
                    for i in 0..len19 {
                      let base = base19.add(i * (2*::core::mem::size_of::<*const u8>()));
                      {
                        let l17 = *base.add(0).cast::<*mut u8>();
                        let l18 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
                        _rt::cabi_dealloc(l17, l18, 1);
                      }
                    }
                    _rt::cabi_dealloc(base19, len19 * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
                  },
                }
              },
              _ => {
                let l20 = *arg0.add(8+1*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                let l21 = *arg0.add(8+2*::core::mem::size_of::<*const u8>()).cast::<usize>();
                _rt::cabi_dealloc(l20, l21, 1);
              },
            }
          } }
          #[doc(hidden)]
          #[allow(non_snake_case, unused_unsafe)]
          pub unsafe fn _export_complete_action_cabi<T: Guest>(arg0: *mut u8,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
          _rt::run_ctors_once();let result45 = {
            let l0 = *arg0.add(0).cast::<i32>();
            let l1 = *arg0.add(8).cast::<*mut u8>();
            let l2 = *arg0.add(8+1*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len3 = l2;
            let bytes3 = _rt::Vec::from_raw_parts(l1.cast(), len3, len3);
            let l4 = *arg0.add(8+2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l5 = *arg0.add(8+3*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len6 = l5;
            let bytes6 = _rt::Vec::from_raw_parts(l4.cast(), len6, len6);
            let l7 = *arg0.add(8+4*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l8 = *arg0.add(8+5*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len9 = l8;
            let bytes9 = _rt::Vec::from_raw_parts(l7.cast(), len9, len9);
            let l10 = i32::from(*arg0.add(8+6*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l11 = i32::from(*arg0.add(9+6*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l12 = *arg0.add(8+7*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l13 = *arg0.add(8+8*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len14 = l13;
            let bytes14 = _rt::Vec::from_raw_parts(l12.cast(), len14, len14);
            let l15 = i32::from(*arg0.add(8+9*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l19 = *arg0.add(8+12*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l20 = *arg0.add(8+13*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let len21 = l20;
            let bytes21 = _rt::Vec::from_raw_parts(l19.cast(), len21, len21);
            let l22 = i32::from(*arg0.add(8+14*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l28 = *arg0.add(32+14*::core::mem::size_of::<*const u8>()).cast::<i64>();
            let l29 = *arg0.add(40+14*::core::mem::size_of::<*const u8>()).cast::<i32>();
            let l30 = *arg0.add(40+15*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l31 = *arg0.add(40+16*::core::mem::size_of::<*const u8>()).cast::<usize>();
            let base35 = l30;
            let len35 = l31;
            let mut result35 = _rt::Vec::with_capacity(len35);
            for i in 0..len35 {
              let base = base35.add(i * (2*::core::mem::size_of::<*const u8>()));
              let e35 = {
                let l32 = *base.add(0).cast::<*mut u8>();
                let l33 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
                let len34 = l33;
                let bytes34 = _rt::Vec::from_raw_parts(l32.cast(), len34, len34);

                _rt::string_lift(bytes34)
              };
              result35.push(e35);
            }
            _rt::cabi_dealloc(base35, len35 * (2*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
            let l36 = i32::from(*arg0.add(48+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l38 = i32::from(*arg0.add(64+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l39 = i32::from(*arg0.add(65+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
            let l40 = *arg0.add(68+16*::core::mem::size_of::<*const u8>()).cast::<f32>();
            let l41 = i32::from(*arg0.add(72+16*::core::mem::size_of::<*const u8>()).cast::<u8>());
            T::complete_action(InstanceBorrow::lift(l0 as u32 as usize), super::super::super::super::ntx::runner::types::ActionResult{
              ctx: super::super::super::super::ntx::runner::types::ActionCtx{
                task_id: _rt::string_lift(bytes3),
                action_id: _rt::string_lift(bytes6),
                user_id: _rt::string_lift(bytes9),
                protocol: super::super::super::super::ntx::runner::types::ProtocolKind::_lift(l10 as u8),
                origin: super::super::super::super::ntx::runner::types::ActionOrigin::_lift(l11 as u8),
                payload: super::super::super::super::ntx::runner::types::PayloadRef{
                  path: _rt::string_lift(bytes14),
                  checksum: match l15 {
                    0 => None,
                    1 => {
                      let e = {
                        let l16 = *arg0.add(8+10*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                        let l17 = *arg0.add(8+11*::core::mem::size_of::<*const u8>()).cast::<usize>();
                        let len18 = l17;
                        let bytes18 = _rt::Vec::from_raw_parts(l16.cast(), len18, len18);

                        _rt::string_lift(bytes18)
                      };
                      Some(e)
                    }
                    _ => _rt::invalid_enum_discriminant(),
                  },
                  format: _rt::string_lift(bytes21),
                },
                rate: match l22 {
                  0 => None,
                  1 => {
                    let e = {
                      let l23 = *arg0.add(12+14*::core::mem::size_of::<*const u8>()).cast::<i32>();
                      let l24 = i32::from(*arg0.add(16+14*::core::mem::size_of::<*const u8>()).cast::<u8>());
                      let l26 = i32::from(*arg0.add(24+14*::core::mem::size_of::<*const u8>()).cast::<u8>());

                      super::super::super::super::ntx::runner::types::RateProfile{
                        bytes_per_tick: l23 as u32,
                        max_burst_bytes: match l24 {
                          0 => None,
                          1 => {
                            let e = {
                              let l25 = *arg0.add(20+14*::core::mem::size_of::<*const u8>()).cast::<i32>();

                              l25 as u32
                            };
                            Some(e)
                          }
                          _ => _rt::invalid_enum_discriminant(),
                        },
                        max_inflight: match l26 {
                          0 => None,
                          1 => {
                            let e = {
                              let l27 = *arg0.add(28+14*::core::mem::size_of::<*const u8>()).cast::<i32>();

                              l27 as u32
                            };
                            Some(e)
                          }
                          _ => _rt::invalid_enum_discriminant(),
                        },
                      }
                    };
                    Some(e)
                  }
                  _ => _rt::invalid_enum_discriminant(),
                },
                tick: l28 as u64,
                attempt: l29 as u32,
                dependencies: result35,
                deadline_ns: match l36 {
                  0 => None,
                  1 => {
                    let e = {
                      let l37 = *arg0.add(56+16*::core::mem::size_of::<*const u8>()).cast::<i64>();

                      l37 as u64
                    };
                    Some(e)
                  }
                  _ => _rt::invalid_enum_discriminant(),
                },
              },
              phase: super::super::super::super::ntx::runner::types::ActionPhase::_lift(l38 as u8),
              outcome: super::super::super::super::ntx::runner::types::ActionResultKind::_lift(l39 as u8),
              progress: l40,
              error_message: match l41 {
                0 => None,
                1 => {
                  let e = {
                    let l42 = *arg0.add(72+17*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                    let l43 = *arg0.add(72+18*::core::mem::size_of::<*const u8>()).cast::<usize>();
                    let len44 = l43;
                    let bytes44 = _rt::Vec::from_raw_parts(l42.cast(), len44, len44);

                    _rt::string_lift(bytes44)
                  };
                  Some(e)
                }
                _ => _rt::invalid_enum_discriminant(),
              },
            })
          };
          _rt::cabi_dealloc(arg0, 80+18*::core::mem::size_of::<*const u8>(), 8);
          let ptr46 = (&raw mut _RET_AREA.0).cast::<u8>();
          match result45 {
            Ok(_) => { {
              *ptr46.add(0).cast::<u8>() = (0i32) as u8;
            } },
            Err(e) => { {
              *ptr46.add(0).cast::<u8>() = (1i32) as u8;
              let super::super::super::super::ntx::runner::types::SchedulerError{ kind:kind47, message:message47, } = e;
              *ptr46.add(::core::mem::size_of::<*const u8>()).cast::<u8>() = (kind47.clone() as i32) as u8;
              let vec48 = (message47.into_bytes()).into_boxed_slice();
              let ptr48 = vec48.as_ptr().cast::<u8>();
              let len48 = vec48.len();
              ::core::mem::forget(vec48);
              *ptr46.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len48;
              *ptr46.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr48.cast_mut();
            } },
          };ptr46
        } }
        #[doc(hidden)]
        #[allow(non_snake_case)]
        pub unsafe fn __post_return_complete_action<T: Guest>(arg0: *mut u8,) { unsafe {
          let l0 = i32::from(*arg0.add(0).cast::<u8>());
          match l0 {
            0 => (),
            _ => {
              let l1 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l2 = *arg0.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l1, l2, 1);
            },
          }
        } }
        #[doc(hidden)]
        #[allow(non_snake_case, unused_unsafe)]
        pub unsafe fn _export_enqueue_cabi<T: Guest>(arg0: i32,arg1: *mut u8,arg2: usize,arg3: *mut u8,arg4: usize,arg5: i32,arg6: i32,arg7: i32,arg8: *mut u8,arg9: usize,arg10: i32,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
        _rt::run_ctors_once();let result3 = {
          let len0 = arg2;
          let bytes0 = _rt::Vec::from_raw_parts(arg1.cast(), len0, len0);
          let len1 = arg4;
          let bytes1 = _rt::Vec::from_raw_parts(arg3.cast(), len1, len1);
          T::enqueue(InstanceBorrow::lift(arg0 as u32 as usize), super::super::super::super::ntx::runner::types::TaskMeta{
            task_id: _rt::string_lift(bytes0),
            workflow_id: _rt::string_lift(bytes1),
            protocol: super::super::super::super::ntx::runner::types::ProtocolKind::_lift(arg5 as u8),
            priority: arg6 as u8,
            template_ref: match arg7 {
              0 => None,
              1 => {
                let e = {
                  let len2 = arg9;
                  let bytes2 = _rt::Vec::from_raw_parts(arg8.cast(), len2, len2);

                  _rt::string_lift(bytes2)
                };
                Some(e)
              }
              _ => _rt::invalid_enum_discriminant(),
            },
            origin: super::super::super::super::ntx::runner::types::ActionOrigin::_lift(arg10 as u8),
          })
        };
        let ptr4 = (&raw mut _RET_AREA.0).cast::<u8>();
        match result3 {
          Ok(e) => { {
            *ptr4.add(0).cast::<u8>() = (0i32) as u8;
            let super::super::super::super::ntx::runner::types::EnqueueResult{ task_id:task_id5, accepted:accepted5, reason:reason5, } = e;
            let vec6 = (task_id5.into_bytes()).into_boxed_slice();
            let ptr6 = vec6.as_ptr().cast::<u8>();
            let len6 = vec6.len();
            ::core::mem::forget(vec6);
            *ptr4.add(2*::core::mem::size_of::<*const u8>()).cast::<usize>() = len6;
            *ptr4.add(::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr6.cast_mut();
            *ptr4.add(3*::core::mem::size_of::<*const u8>()).cast::<u8>() = (match accepted5 { true => 1, false => 0 }) as u8;
            match reason5 {
              Some(e) => {
                *ptr4.add(4*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                let vec7 = (e.into_bytes()).into_boxed_slice();
                let ptr7 = vec7.as_ptr().cast::<u8>();
                let len7 = vec7.len();
                ::core::mem::forget(vec7);
                *ptr4.add(6*::core::mem::size_of::<*const u8>()).cast::<usize>() = len7;
                *ptr4.add(5*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr7.cast_mut();
              },
              None => {
                {
                  *ptr4.add(4*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                }
              },
            };} },
            Err(e) => { {
              *ptr4.add(0).cast::<u8>() = (1i32) as u8;
              let super::super::super::super::ntx::runner::types::SchedulerError{ kind:kind8, message:message8, } = e;
              *ptr4.add(::core::mem::size_of::<*const u8>()).cast::<u8>() = (kind8.clone() as i32) as u8;
              let vec9 = (message8.into_bytes()).into_boxed_slice();
              let ptr9 = vec9.as_ptr().cast::<u8>();
              let len9 = vec9.len();
              ::core::mem::forget(vec9);
              *ptr4.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len9;
              *ptr4.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr9.cast_mut();
            } },
          };ptr4
        } }
        #[doc(hidden)]
        #[allow(non_snake_case)]
        pub unsafe fn __post_return_enqueue<T: Guest>(arg0: *mut u8,) { unsafe {
          let l0 = i32::from(*arg0.add(0).cast::<u8>());
          match l0 {
            0 => {
              let l1 = *arg0.add(::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l2 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l1, l2, 1);
              let l3 = i32::from(*arg0.add(4*::core::mem::size_of::<*const u8>()).cast::<u8>());
              match l3 {
                0 => (),
                _ => {
                  let l4 = *arg0.add(5*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                  let l5 = *arg0.add(6*::core::mem::size_of::<*const u8>()).cast::<usize>();
                  _rt::cabi_dealloc(l4, l5, 1);
                },
              }
            },
            _ => {
              let l6 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
              let l7 = *arg0.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
              _rt::cabi_dealloc(l6, l7, 1);
            },
          }
        } }
        #[doc(hidden)]
        #[allow(non_snake_case, unused_unsafe)]
        pub unsafe fn _export_snapshot_cabi<T: Guest>(arg0: i32,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
        _rt::run_ctors_once();let result0 = {
          T::snapshot(InstanceBorrow::lift(arg0 as u32 as usize))
        };
        let ptr1 = (&raw mut _RET_AREA.0).cast::<u8>();
        let vec6 = result0;
        let len6 = vec6.len();
        let layout6 = _rt::alloc::Layout::from_size_align(vec6.len() * (9*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>()).unwrap();
        let (result6, _cleanup6) = wit_bindgen::rt::Cleanup::new(layout6);if let Some(cleanup) = _cleanup6 { cleanup.forget(); }
        for (i, e) in vec6.into_iter().enumerate() {
          let base = result6.add(i * (9*::core::mem::size_of::<*const u8>()));
          {
            let super::super::super::super::ntx::runner::types::TaskMeta{ task_id:task_id2, workflow_id:workflow_id2, protocol:protocol2, priority:priority2, template_ref:template_ref2, origin:origin2, } = e;
            let vec3 = (task_id2.into_bytes()).into_boxed_slice();
            let ptr3 = vec3.as_ptr().cast::<u8>();
            let len3 = vec3.len();
            ::core::mem::forget(vec3);
            *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>() = len3;
            *base.add(0).cast::<*mut u8>() = ptr3.cast_mut();
            let vec4 = (workflow_id2.into_bytes()).into_boxed_slice();
            let ptr4 = vec4.as_ptr().cast::<u8>();
            let len4 = vec4.len();
            ::core::mem::forget(vec4);
            *base.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len4;
            *base.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr4.cast_mut();
            *base.add(4*::core::mem::size_of::<*const u8>()).cast::<u8>() = (protocol2.clone() as i32) as u8;
            *base.add(1+4*::core::mem::size_of::<*const u8>()).cast::<u8>() = (_rt::as_i32(priority2)) as u8;
            match template_ref2 {
              Some(e) => {
                *base.add(5*::core::mem::size_of::<*const u8>()).cast::<u8>() = (1i32) as u8;
                let vec5 = (e.into_bytes()).into_boxed_slice();
                let ptr5 = vec5.as_ptr().cast::<u8>();
                let len5 = vec5.len();
                ::core::mem::forget(vec5);
                *base.add(7*::core::mem::size_of::<*const u8>()).cast::<usize>() = len5;
                *base.add(6*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr5.cast_mut();
              },
              None => {
                {
                  *base.add(5*::core::mem::size_of::<*const u8>()).cast::<u8>() = (0i32) as u8;
                }
              },
            };*base.add(8*::core::mem::size_of::<*const u8>()).cast::<u8>() = (origin2.clone() as i32) as u8;
          }
        }
        *ptr1.add(::core::mem::size_of::<*const u8>()).cast::<usize>() = len6;
        *ptr1.add(0).cast::<*mut u8>() = result6;
        ptr1
      } }
      #[doc(hidden)]
      #[allow(non_snake_case)]
      pub unsafe fn __post_return_snapshot<T: Guest>(arg0: *mut u8,) { unsafe {
        let l0 = *arg0.add(0).cast::<*mut u8>();
        let l1 = *arg0.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
        let base9 = l0;
        let len9 = l1;
        for i in 0..len9 {
          let base = base9.add(i * (9*::core::mem::size_of::<*const u8>()));
          {
            let l2 = *base.add(0).cast::<*mut u8>();
            let l3 = *base.add(::core::mem::size_of::<*const u8>()).cast::<usize>();
            _rt::cabi_dealloc(l2, l3, 1);
            let l4 = *base.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
            let l5 = *base.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
            _rt::cabi_dealloc(l4, l5, 1);
            let l6 = i32::from(*base.add(5*::core::mem::size_of::<*const u8>()).cast::<u8>());
            match l6 {
              0 => (),
              _ => {
                let l7 = *base.add(6*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
                let l8 = *base.add(7*::core::mem::size_of::<*const u8>()).cast::<usize>();
                _rt::cabi_dealloc(l7, l8, 1);
              },
            }
          }
        }
        _rt::cabi_dealloc(base9, len9 * (9*::core::mem::size_of::<*const u8>()), ::core::mem::size_of::<*const u8>());
      } }
      #[doc(hidden)]
      #[allow(non_snake_case, unused_unsafe)]
      pub unsafe fn _export_drain_cabi<T: Guest>(arg0: i32,) -> *mut u8 { unsafe {#[cfg(target_arch="wasm32")]
      _rt::run_ctors_once();let result0 = {
        T::drain(Instance::from_handle(arg0 as u32))
      };
      let ptr1 = (&raw mut _RET_AREA.0).cast::<u8>();
      match result0 {
        Ok(_) => { {
          *ptr1.add(0).cast::<u8>() = (0i32) as u8;
        } },
        Err(e) => { {
          *ptr1.add(0).cast::<u8>() = (1i32) as u8;
          let super::super::super::super::ntx::runner::types::SchedulerError{ kind:kind2, message:message2, } = e;
          *ptr1.add(::core::mem::size_of::<*const u8>()).cast::<u8>() = (kind2.clone() as i32) as u8;
          let vec3 = (message2.into_bytes()).into_boxed_slice();
          let ptr3 = vec3.as_ptr().cast::<u8>();
          let len3 = vec3.len();
          ::core::mem::forget(vec3);
          *ptr1.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>() = len3;
          *ptr1.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>() = ptr3.cast_mut();
        } },
      };ptr1
    } }
    #[doc(hidden)]
    #[allow(non_snake_case)]
    pub unsafe fn __post_return_drain<T: Guest>(arg0: *mut u8,) { unsafe {
      let l0 = i32::from(*arg0.add(0).cast::<u8>());
      match l0 {
        0 => (),
        _ => {
          let l1 = *arg0.add(2*::core::mem::size_of::<*const u8>()).cast::<*mut u8>();
          let l2 = *arg0.add(3*::core::mem::size_of::<*const u8>()).cast::<usize>();
          _rt::cabi_dealloc(l1, l2, 1);
        },
      }
    } }
    pub trait Guest {
      type Instance: GuestInstance;
      /// Initialize scheduler state for a workflow plus its static tasks.
      #[allow(async_fn_in_trait)]
      fn init(cfg: SchedulerConfig,tasks: _rt::Vec::<TaskMeta>,) -> Result<Instance,SchedulerError>;
      /// Fetch the next runnable action context, respecting the provided budget.
      #[allow(async_fn_in_trait)]
      fn poll_action(inst: InstanceBorrow<'_>,max_users: u32,) -> Result<Option<ActionCtx>,SchedulerError>;
      /// Commit the outcome of an action run by a Protocol.
      #[allow(async_fn_in_trait)]
      fn complete_action(inst: InstanceBorrow<'_>,outcome: ActionResult,) -> Result<(),SchedulerError>;
      /// Enqueue a new (possibly dynamic) task originating from ProtocolFrame.
      #[allow(async_fn_in_trait)]
      fn enqueue(inst: InstanceBorrow<'_>,task: TaskMeta,) -> Result<EnqueueResult,SchedulerError>;
      /// Return a snapshot of registered tasks for observability or debugging.
      #[allow(async_fn_in_trait)]
      fn snapshot(inst: InstanceBorrow<'_>,) -> _rt::Vec::<TaskMeta>;
      /// Gracefully drain pending work and release scheduler resources.
      #[allow(async_fn_in_trait)]
      fn drain(inst: Instance,) -> Result<(),SchedulerError>;
    }
    pub trait GuestInstance: 'static {

      #[doc(hidden)]
      unsafe fn _resource_new(val: *mut u8) -> u32
      where Self: Sized
      {
        
        #[cfg(target_arch = "wasm32")]
        #[link(wasm_import_module = "[export]ntx:runner/core-scheduler")]
        unsafe extern "C" {
          #[link_name = "[resource-new]instance"]
          fn new(_: *mut u8, ) -> i32;
        }

        #[cfg(not(target_arch = "wasm32"))]
        unsafe extern "C" fn new(_: *mut u8, ) -> i32 { unreachable!() }
        
        unsafe { new(val) as u32 }
      }

      #[doc(hidden)]
      fn _resource_rep(handle: u32) -> *mut u8
      where Self: Sized
      {
        
        #[cfg(target_arch = "wasm32")]
        #[link(wasm_import_module = "[export]ntx:runner/core-scheduler")]
        unsafe extern "C" {
          #[link_name = "[resource-rep]instance"]
          fn rep(_: i32, ) -> *mut u8;
        }

        #[cfg(not(target_arch = "wasm32"))]
        unsafe extern "C" fn rep(_: i32, ) -> *mut u8 { unreachable!() }
        
        unsafe { rep(handle as i32) }
      }

      
    }
    #[doc(hidden)]

    macro_rules! __export_ntx_runner_core_scheduler_cabi{
      ($ty:ident with_types_in $($path_to_types:tt)*) => (const _: () = {

        #[unsafe(export_name = "ntx:runner/core-scheduler#init")]
        unsafe extern "C" fn export_init(arg0: *mut u8,arg1: usize,arg2: i32,arg3: i32,arg4: i32,arg5: i32,arg6: *mut u8,arg7: usize,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_init_cabi::<$ty>(arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#init")]
        unsafe extern "C" fn _post_return_init(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_init::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/core-scheduler#poll-action")]
        unsafe extern "C" fn export_poll_action(arg0: i32,arg1: i32,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_poll_action_cabi::<$ty>(arg0, arg1) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#poll-action")]
        unsafe extern "C" fn _post_return_poll_action(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_poll_action::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/core-scheduler#complete-action")]
        unsafe extern "C" fn export_complete_action(arg0: *mut u8,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_complete_action_cabi::<$ty>(arg0) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#complete-action")]
        unsafe extern "C" fn _post_return_complete_action(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_complete_action::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/core-scheduler#enqueue")]
        unsafe extern "C" fn export_enqueue(arg0: i32,arg1: *mut u8,arg2: usize,arg3: *mut u8,arg4: usize,arg5: i32,arg6: i32,arg7: i32,arg8: *mut u8,arg9: usize,arg10: i32,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_enqueue_cabi::<$ty>(arg0, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#enqueue")]
        unsafe extern "C" fn _post_return_enqueue(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_enqueue::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/core-scheduler#snapshot")]
        unsafe extern "C" fn export_snapshot(arg0: i32,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_snapshot_cabi::<$ty>(arg0) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#snapshot")]
        unsafe extern "C" fn _post_return_snapshot(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_snapshot::<$ty>(arg0) }
        }
        #[unsafe(export_name = "ntx:runner/core-scheduler#drain")]
        unsafe extern "C" fn export_drain(arg0: i32,) -> *mut u8 {
          unsafe { $($path_to_types)*::_export_drain_cabi::<$ty>(arg0) }
        }
        #[unsafe(export_name = "cabi_post_ntx:runner/core-scheduler#drain")]
        unsafe extern "C" fn _post_return_drain(arg0: *mut u8,) {
          unsafe { $($path_to_types)*::__post_return_drain::<$ty>(arg0) }
        }

        const _: () = {
          #[doc(hidden)]
          #[unsafe(export_name = "ntx:runner/core-scheduler#[dtor]instance")]
          #[allow(non_snake_case)]
          unsafe extern "C" fn dtor(rep: *mut u8) {
            unsafe {
              $($path_to_types)*::Instance::dtor::<
              <$ty as $($path_to_types)*::Guest>::Instance
              >(rep)
            }
          }
        };
        
      };);
    }
    #[doc(hidden)]
    pub(crate) use __export_ntx_runner_core_scheduler_cabi;

    #[repr(align(8))]
    struct _RetArea([::core::mem::MaybeUninit::<u8>; 72+16*::core::mem::size_of::<*const u8>()]);
    static mut _RET_AREA: _RetArea = _RetArea([::core::mem::MaybeUninit::uninit(); 72+16*::core::mem::size_of::<*const u8>()]);

  }

}
}
}
mod _rt {
  #![allow(dead_code, clippy::all)]
  pub use alloc_crate::string::String;
  pub use alloc_crate::vec::Vec;


  use core::fmt;
  use core::marker;
  use core::sync::atomic::{AtomicU32, Ordering::Relaxed};

  /// A type which represents a component model resource, either imported or
  /// exported into this component.
  ///
  /// This is a low-level wrapper which handles the lifetime of the resource
  /// (namely this has a destructor). The `T` provided defines the component model
  /// intrinsics that this wrapper uses.
  ///
  /// One of the chief purposes of this type is to provide `Deref` implementations
  /// to access the underlying data when it is owned.
  ///
  /// This type is primarily used in generated code for exported and imported
  /// resources.
  #[repr(transparent)]
  pub struct Resource<T: WasmResource> {
    // NB: This would ideally be `u32` but it is not. The fact that this has
    // interior mutability is not exposed in the API of this type except for the
    // `take_handle` method which is supposed to in theory be private.
    //
    // This represents, almost all the time, a valid handle value. When it's
    // invalid it's stored as `u32::MAX`.
    handle: AtomicU32,
    _marker: marker::PhantomData<T>,
  }

  /// A trait which all wasm resources implement, namely providing the ability to
  /// drop a resource.
  ///
  /// This generally is implemented by generated code, not user-facing code.
  #[allow(clippy::missing_safety_doc)]
  pub unsafe trait WasmResource {
    /// Invokes the `[resource-drop]...` intrinsic.
    unsafe fn drop(handle: u32);
  }

  impl<T: WasmResource> Resource<T> {
    #[doc(hidden)]
    pub unsafe fn from_handle(handle: u32) -> Self {
      debug_assert!(handle != 0 && handle != u32::MAX);
      Self {
        handle: AtomicU32::new(handle),
        _marker: marker::PhantomData,
      }
    }

    /// Takes ownership of the handle owned by `resource`.
    ///
    /// Note that this ideally would be `into_handle` taking `Resource<T>` by
    /// ownership. The code generator does not enable that in all situations,
    /// unfortunately, so this is provided instead.
    ///
    /// Also note that `take_handle` is in theory only ever called on values
    /// owned by a generated function. For example a generated function might
    /// take `Resource<T>` as an argument but then call `take_handle` on a
    /// reference to that argument. In that sense the dynamic nature of
    /// `take_handle` should only be exposed internally to generated code, not
    /// to user code.
    #[doc(hidden)]
    pub fn take_handle(resource: &Resource<T>) -> u32 {
      resource.handle.swap(u32::MAX, Relaxed)
    }

    #[doc(hidden)]
    pub fn handle(resource: &Resource<T>) -> u32 {
      resource.handle.load(Relaxed)
    }
  }

  impl<T: WasmResource> fmt::Debug for Resource<T> {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
      f.debug_struct("Resource")
      .field("handle", &self.handle)
      .finish()
    }
  }

  impl<T: WasmResource> Drop for Resource<T> {
    fn drop(&mut self) {
      unsafe {
        match self.handle.load(Relaxed) {
          // If this handle was "taken" then don't do anything in the
          // destructor.
          u32::MAX => {}

          // ... but otherwise do actually destroy it with the imported
          // component model intrinsic as defined through `T`.
          other => T::drop(other),
        }
      }
    }
  }
  pub use alloc_crate::boxed::Box;

  #[cfg(target_arch = "wasm32")]
  pub fn run_ctors_once() {
    wit_bindgen::rt::run_ctors_once();
  }
  pub unsafe fn string_lift(bytes: Vec<u8>) -> String {
    if cfg!(debug_assertions) {
      String::from_utf8(bytes).unwrap()
    } else {
      unsafe { String::from_utf8_unchecked(bytes) }
    }
  }
  pub unsafe fn invalid_enum_discriminant<T>() -> T {
    if cfg!(debug_assertions) {
      panic!("invalid enum discriminant")
    } else {
      unsafe { core::hint::unreachable_unchecked() }
    }
  }
  pub unsafe fn cabi_dealloc(ptr: *mut u8, size: usize, align: usize) {
    if size == 0 {
      return;
    }
    unsafe {
      let layout = alloc::Layout::from_size_align_unchecked(size, align);
      alloc::dealloc(ptr, layout);
    }
  }
  
  pub fn as_i32<T: AsI32>(t: T) -> i32 {
    t.as_i32()
  }

  pub trait AsI32 {
    fn as_i32(self) -> i32;
  }

  impl<'a, T: Copy + AsI32> AsI32 for &'a T {
    fn as_i32(self) -> i32 {
      (*self).as_i32()
    }
  }
  
  impl AsI32 for i32 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u32 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for i16 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u16 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for i8 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for u8 {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for char {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  impl AsI32 for usize {
    #[inline]
    fn as_i32(self) -> i32 {
      self as i32
    }
  }
  
  pub fn as_i64<T: AsI64>(t: T) -> i64 {
    t.as_i64()
  }

  pub trait AsI64 {
    fn as_i64(self) -> i64;
  }

  impl<'a, T: Copy + AsI64> AsI64 for &'a T {
    fn as_i64(self) -> i64 {
      (*self).as_i64()
    }
  }
  
  impl AsI64 for i64 {
    #[inline]
    fn as_i64(self) -> i64 {
      self as i64
    }
  }
  
  impl AsI64 for u64 {
    #[inline]
    fn as_i64(self) -> i64 {
      self as i64
    }
  }
  pub use alloc_crate::alloc;
  extern crate alloc as alloc_crate;
}

/// Generates `#[unsafe(no_mangle)]` functions to export the specified type as
/// the root implementation of all generated traits.
///
/// For more information see the documentation of `wit_bindgen::generate!`.
///
/// ```rust
/// # macro_rules! export{ ($($t:tt)*) => (); }
/// # trait Guest {}
/// struct MyType;
///
/// impl Guest for MyType {
///     // ...
/// }
///
/// export!(MyType);
/// ```
#[allow(unused_macros)]
#[doc(hidden)]

macro_rules! __export_scheduler_world_impl {
  ($ty:ident) => (self::export!($ty with_types_in self););
  ($ty:ident with_types_in $($path_to_types_root:tt)*) => (
  $($path_to_types_root)*::exports::ntx::runner::core_scheduler::__export_ntx_runner_core_scheduler_cabi!($ty with_types_in $($path_to_types_root)*::exports::ntx::runner::core_scheduler);
  )
}
#[doc(inline)]
pub(crate) use __export_scheduler_world_impl as export;

#[cfg(target_arch = "wasm32")]
#[unsafe(link_section = "component-type:wit-bindgen:0.48.0:ntx:runner:scheduler-world:encoded world")]
#[doc(hidden)]
#[allow(clippy::octal_escapes)]
pub static __WIT_BINDGEN_COMPONENT_TYPE: [u8; 1976] = *b"\
\0asm\x0d\0\x01\0\0\x19\x16wit-component-encoding\x04\0\x07\xb2\x0e\x01A\x02\x01\
A\x0a\x01B3\x01s\x04\0\x07task-id\x03\0\0\x01s\x04\0\x07user-id\x03\0\x02\x01s\x04\
\0\x09action-id\x03\0\x04\x01m\x04\x04http\x03ftp\x09tcp-probe\x06custom\x04\0\x0d\
protocol-kind\x03\0\x06\x01m\x02\x0bhost-script\x11runtime-generated\x04\0\x0dac\
tion-origin\x03\0\x08\x01m\x06\x07pending\x07running\x07waiting\x08retrying\x09c\
ompleted\x06failed\x04\0\x0caction-phase\x03\0\x0a\x01m\x03\x07success\x07skippe\
d\x06failed\x04\0\x12action-result-kind\x03\0\x0c\x01m\x05\x0binvalid-ctx\x08cap\
acity\x02io\x07timeout\x08internal\x04\0\x14scheduler-error-kind\x03\0\x0e\x01m\x04\
\x0finvalid-request\x09throttled\x09not-found\x08internal\x04\0\x0dpf-error-kind\
\x03\0\x10\x01n\x06\x06logger\x05timer\x06socket\x0arate-guard\x08progress\x0aca\
ll-model\x04\0\x0dpf-capability\x03\0\x12\x01ky\x01r\x04\x0bworkflow-ids\x10tick\
-duration-msy\x0fmax-concurrencyy\x0cwarmup-ticks\x14\x04\0\x10scheduler-config\x03\
\0\x15\x01r\x03\x0ebytes-per-ticky\x0fmax-burst-bytes\x14\x0cmax-inflight\x14\x04\
\0\x0crate-profile\x03\0\x17\x01ks\x01r\x06\x07task-id\x01\x0bworkflow-ids\x08pr\
otocol\x07\x08priority}\x0ctemplate-ref\x19\x06origin\x09\x04\0\x09task-meta\x03\
\0\x1a\x01k\x7f\x01r\x03\x04hosts\x04port{\x03tls\x1c\x04\0\x08endpoint\x03\0\x1d\
\x01r\x03\x04paths\x08checksum\x19\x06formats\x04\0\x0bpayload-ref\x03\0\x1f\x01\
k\x18\x01p\x05\x01kw\x01r\x0b\x07task-id\x01\x09action-id\x05\x07user-id\x03\x08\
protocol\x07\x06origin\x09\x07payload\x20\x04rate!\x04tickw\x07attempty\x0cdepen\
dencies\"\x0bdeadline-ns#\x04\0\x0aaction-ctx\x03\0$\x01r\x05\x03ctx%\x05phase\x0b\
\x07outcome\x0d\x08progressv\x0derror-message\x19\x04\0\x0daction-result\x03\0&\x01\
r\x03\x07task-id\x01\x08accepted\x7f\x06reason\x19\x04\0\x0eenqueue-result\x03\0\
(\x01r\x02\x04kind\x0f\x07messages\x04\0\x0fscheduler-error\x03\0*\x01r\x02\x04k\
ind\x11\x07messages\x04\0\x08pf-error\x03\0,\x01p\x13\x01r\x05\x05pf-ids\x0bwork\
flow-ids\x0ccapabilities.\x0cresource-dirs\x0auser-county\x04\0\x11protocol-init\
-ctx\x03\0/\x01r\x03\x07user-id\x03\x09blob-paths\x0dupdated-at-nsw\x04\0\x10use\
r-store-entry\x03\01\x03\0\x10ntx:runner/types\x05\0\x02\x03\0\0\x10scheduler-co\
nfig\x02\x03\0\0\x09task-meta\x02\x03\0\0\x0aaction-ctx\x02\x03\0\0\x0daction-re\
sult\x02\x03\0\0\x0eenqueue-result\x02\x03\0\0\x0fscheduler-error\x01B!\x02\x03\x02\
\x01\x01\x04\0\x10scheduler-config\x03\0\0\x02\x03\x02\x01\x02\x04\0\x09task-met\
a\x03\0\x02\x02\x03\x02\x01\x03\x04\0\x0aaction-ctx\x03\0\x04\x02\x03\x02\x01\x04\
\x04\0\x0daction-result\x03\0\x06\x02\x03\x02\x01\x05\x04\0\x0eenqueue-result\x03\
\0\x08\x02\x03\x02\x01\x06\x04\0\x0fscheduler-error\x03\0\x0a\x04\0\x08instance\x03\
\x01\x01p\x03\x01i\x0c\x01j\x01\x0e\x01\x0b\x01@\x02\x03cfg\x01\x05tasks\x0d\0\x0f\
\x04\0\x04init\x01\x10\x01h\x0c\x01k\x05\x01j\x01\x12\x01\x0b\x01@\x02\x04inst\x11\
\x09max-usersy\0\x13\x04\0\x0bpoll-action\x01\x14\x01j\0\x01\x0b\x01@\x02\x04ins\
t\x11\x07outcome\x07\0\x15\x04\0\x0fcomplete-action\x01\x16\x01j\x01\x09\x01\x0b\
\x01@\x02\x04inst\x11\x04task\x03\0\x17\x04\0\x07enqueue\x01\x18\x01@\x01\x04ins\
t\x11\0\x0d\x04\0\x08snapshot\x01\x19\x01@\x01\x04inst\x0e\0\x15\x04\0\x05drain\x01\
\x1a\x04\0\x19ntx:runner/core-scheduler\x05\x07\x04\0\x1antx:runner/scheduler-wo\
rld\x04\0\x0b\x15\x01\0\x0fscheduler-world\x03\0\0\0G\x09producers\x01\x0cproces\
sed-by\x02\x0dwit-component\x070.241.2\x10wit-bindgen-rust\x060.48.0";

#[inline(never)]
#[doc(hidden)]
pub fn __link_custom_section_describing_imports() {
  wit_bindgen::rt::maybe_link_cabi_realloc();
}

